{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import random, csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import adapt\n",
    "from adapt.feature_based import DANN, CORAL, DeepCORAL, CDAN\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# The path of the datasets, use dict format\n",
    "path = \"I:/Temp/CS 766 CCPD Data\"\n",
    "dataset_path = {\"base\": path + \"/ccpd/splitted_plates_base\",\n",
    "                \"challenge\": path + \"/ccpd/splitted_plates_challenge\",\n",
    "                \"db\": path + \"/ccpd/splitted_plates_db\",\n",
    "                \"fn\": path + \"/ccpd/splitted_plates_fn\",\n",
    "                \"weather\": path + \"/ccpd/splitted_plates_weather\"}\n",
    "img_h, img_w = 32, 16\n",
    "save_check_pt = './checkpoints_Coral'\n",
    "\n",
    "\n",
    "def load_csv(root, filename, name2label):\n",
    "    # From csv file return images dir,labels list\n",
    "    if not os.path.exists(os.path.join(root, filename)):\n",
    "        images = []\n",
    "        for name in name2label.keys():\n",
    "            images += glob.glob(os.path.join(root, name, '*.png'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpg'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpeg'))\n",
    "        #print(len(images), images)\n",
    "        random.shuffle(images)  # shuffle images\n",
    "        with open(os.path.join(root, filename), mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for img in images:\n",
    "                name = img.split(os.sep)[-2]\n",
    "                label = name2label[name]\n",
    "                writer.writerow([img, label])\n",
    "            print('written into csv file:', filename)\n",
    "    # read existed csv\n",
    "    images, labels = [], []\n",
    "    with open(os.path.join(root, filename)) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            img, label = row\n",
    "            label = int(label)\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    # return img dir and label\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_ccpd(root, mode='train'):\n",
    "    name2label = {}  # \"sq...\":0\n",
    "    # iterate sub dir, sort, while keep mapping\n",
    "    for name in sorted(os.listdir(os.path.join(root))):\n",
    "        # skip non file folder\n",
    "        if not os.path.isdir(os.path.join(root, name)):\n",
    "            continue\n",
    "        # give each category a number\n",
    "        name2label[name] = len(name2label.keys())\n",
    "    images, labels = load_csv(root, 'images.csv', name2label)\n",
    "    if mode == 'train':  # 20%\n",
    "        images = images[:int(0.2 * len(images))]\n",
    "        labels = labels[:int(0.2 * len(labels))]\n",
    "    elif mode == 'val':  # 20% = 60%->80%\n",
    "        images = images[int(0.6 * len(images)):int(0.8 * len(images))]\n",
    "        labels = labels[int(0.6 * len(labels)):int(0.8 * len(labels))]\n",
    "    else:  # all\n",
    "        images = images\n",
    "        labels = labels\n",
    "    return images, labels, name2label\n",
    "\n",
    "\n",
    "def readCcpdImg(images_dir):\n",
    "    X = []\n",
    "    for img_dir in images_dir:\n",
    "        img = Image.open(img_dir)\n",
    "        img = img.convert('L')  # conver to grayscale images\n",
    "        img = img.resize([img_w, img_h])\n",
    "        img_np = np.asarray(img)\n",
    "        X.append(img_np.reshape([-1]))\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def readCcpdImg_noreshape(images_dir):\n",
    "    X = []\n",
    "    for img_dir in images_dir:\n",
    "        img = Image.open(img_dir)\n",
    "        img = img.convert('L')  # conver to grayscale images\n",
    "        img = img.resize([img_w, img_h])\n",
    "        img_np = np.asarray(img)\n",
    "        X.append(img_np)\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def get_img_label(path, mode, num_classes=35):\n",
    "    images_dir, labels, table = load_ccpd(dataset_path[path], mode=mode)\n",
    "    images = readCcpdImg(images_dir)\n",
    "    labels = np.array(labels)\n",
    "    labels = to_categorical(labels, num_classes=num_classes)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def get_encoder(input_shape=(512,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu',\n",
    "                    input_shape=input_shape))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dense(128, activation=\"sigmoid\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_task(input_shape=(128,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(34, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "# def get_discriminator(input_shape=(128,)):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(128, activation='relu', input_shape=input_shape))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     return model\n",
    "\n",
    "\n",
    "base_images, base_labels = get_img_label('base', 'all', num_classes=34)\n",
    "weather_images, weather_labels = get_img_label('weather', 'all', num_classes=34)\n",
    "weather_images_t, weather_labels_t = get_img_label('weather', 'train', num_classes=34)\n",
    "challenge_images, challenge_labels = get_img_label('challenge', 'all', num_classes=34)\n",
    "challenge_images_t, challenge_labels_t = get_img_label('challenge', 'train', num_classes=34)\n",
    "db_images, db_labels = get_img_label('db', 'all', num_classes=34)\n",
    "db_images_t, db_labels_t = get_img_label('db', 'train', num_classes=34)\n",
    "fn_images, fn_labels = get_img_label('fn', 'all', num_classes=34)\n",
    "fn_images_t, fn_labels_t = get_img_label('fn', 'train', num_classes=34)\n",
    "print(\"load data finished!\")\n",
    "from keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(base_labels))\n",
    "print(np.shape(weather_images_t))\n",
    "print(np.shape(weather_labels_t))\n",
    "\n",
    "weather_model = CDAN(encoder=get_encoder(), task=get_task(),\n",
    "                     lambda_=1, optimizer=Adam(0.0001), loss='CategoricalCrossentropy', metrics=[\"acc\"], random_state=0)\n",
    "weather_model.fit(base_images, base_labels, weather_images_t, weather_labels_t, epochs=80, verbose=1, batch_size=32)\n",
    "weather_model.score(base_images, base_labels)\n",
    "weather_model.score(weather_images, weather_labels)\n",
    "weather_model.save_weights(save_check_pt+ '/weather')\n",
    "\n",
    "challenge_model = CDAN(get_encoder(), get_task(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "challenge_model.fit(base_images, base_labels,challenge_images_t,challenge_labels_t, epochs=88,verbose=1,batch_size = 32)\n",
    "challenge_model.score(base_images, base_labels)\n",
    "challenge_model.score(challenge_images, challenge_labels)\n",
    "challenge_model.save_weights(save_check_pt+ '/challenge')\n",
    "\n",
    "db_model = CDAN(get_encoder(), get_task(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "db_model.fit(base_images, base_labels,db_images_t,db_labels_t, epochs=80,verbose=1,batch_size = 32)\n",
    "db_model.score(base_images, base_labels)\n",
    "db_model.score(db_images, db_labels)\n",
    "db_model.save_weights(save_check_pt+ '/db')\n",
    "\n",
    "fn_model = CDAN(get_encoder(), get_task(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "fn_model.fit(base_images, base_labels,fn_images_t,fn_labels_t, epochs=70,verbose=1,batch_size = 32)\n",
    "fn_model.score(base_images, base_labels)\n",
    "fn_model.score(fn_images, fn_labels)\n",
    "fn_model.save_weights(save_check_pt+ '/fn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}