{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2410689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data finished!\n"
     ]
    }
   ],
   "source": [
    "import  os, glob\n",
    "import  random, csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import adapt\n",
    "from adapt.feature_based import DANN\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# The path of the datasets, use dict format\n",
    "dataset_path = {\"base\": \"dataset/ccpd/splitted_plates_base\", \n",
    "                \"challenge\":\"dataset/ccpd/splitted_plates_challenge\",\n",
    "               \"db\":\"dataset/ccpd/splitted_plates_db\",\n",
    "               \"fn\":\"dataset/ccpd/splitted_plates_fn\",\n",
    "               \"weather\":\"dataset/ccpd/splitted_plates_weather\"}\n",
    "save_check_pt = './checkpoints_DANN'\n",
    "\n",
    "def load_csv(root, filename, name2label):\n",
    "    # From csv file return images dir,labels list\n",
    "    if not os.path.exists(os.path.join(root, filename)):\n",
    "        images = []\n",
    "        for name in name2label.keys(): \n",
    "            images += glob.glob(os.path.join(root, name, '*.png'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpg'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpeg'))\n",
    "        #print(len(images), images)\n",
    "        random.shuffle(images) # shuffle images\n",
    "        with open(os.path.join(root, filename), mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for img in images:  \n",
    "                name = img.split(os.sep)[-2]\n",
    "                label = name2label[name]\n",
    "                writer.writerow([img, label])\n",
    "            print('written into csv file:', filename)\n",
    "    # read existed csv\n",
    "    images, labels = [], []\n",
    "    with open(os.path.join(root, filename)) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            img, label = row\n",
    "            label = int(label)\n",
    "            images.append(img)\n",
    "            labels.append(label) \n",
    "    # return img dir and label\n",
    "    return images, labels\n",
    "\n",
    "def load_ccpd(root, mode='train'):\n",
    "    name2label = {}  # \"sq...\":0\n",
    "    # iterate sub dir, sort, while keep mapping\n",
    "    for name in sorted(os.listdir(os.path.join(root))):\n",
    "        # skip non file folder\n",
    "        if not os.path.isdir(os.path.join(root, name)):\n",
    "            continue\n",
    "        # give each category a number\n",
    "        name2label[name] = len(name2label.keys())\n",
    "    images, labels = load_csv(root, 'images.csv', name2label)\n",
    "    if mode == 'train':  # 20%\n",
    "        images = images[:int(0.2 * len(images))]\n",
    "        labels = labels[:int(0.2 * len(labels))]\n",
    "    elif mode == 'val':  # 20% = 60%->80%\n",
    "        images = images[int(0.6 * len(images)):int(0.8 * len(images))]\n",
    "        labels = labels[int(0.6 * len(labels)):int(0.8 * len(labels))]\n",
    "    else:  # all\n",
    "        images = images\n",
    "        labels = labels\n",
    "    return images, labels, name2label\n",
    "\n",
    "# def readCcpdImg(images_dir):\n",
    "#     X = []\n",
    "#     for img_dir in images_dir:\n",
    "#         img = cv2.imread(img_dir)\n",
    "#         img = cv2.resize(img,(32,32))\n",
    "#         X.append(img)\n",
    "#     X = np.array(X)\n",
    "#     return X\n",
    "\n",
    "def readCcpdImg(images_dir):\n",
    "    X = []\n",
    "    for img_dir in images_dir:\n",
    "        img = Image.open(img_dir)\n",
    "        img = img.convert('L') # conver to grayscale images\n",
    "        img = img.resize([32, 16])\n",
    "        img_np = np.asarray(img)\n",
    "        X.append(img_np.reshape([-1]))\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "def get_img_label(path, mode,num_classes=35):\n",
    "    images_dir, labels, table = load_ccpd(dataset_path[path],mode=mode)\n",
    "    images = readCcpdImg(images_dir)\n",
    "    labels = np.array(labels)\n",
    "    labels = to_categorical(labels, num_classes=num_classes)\n",
    "    return images,labels\n",
    "\n",
    "def get_encoder(input_shape=(512,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu',\n",
    "                    input_shape=input_shape))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dense(128, activation=\"sigmoid\"))\n",
    "    return model\n",
    "\n",
    "def get_task(input_shape=(128,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu',input_shape=input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(34, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "def get_discriminator(input_shape=(128,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu',input_shape=input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "base_images,base_labels = get_img_label('base', 'all', num_classes=34)\n",
    "weather_images,weather_labels = get_img_label('weather', 'all', num_classes=34)\n",
    "weather_images_t,weather_labels_t = get_img_label('weather', 'train', num_classes=34)\n",
    "challenge_images,challenge_labels = get_img_label('challenge', 'all', num_classes=34)\n",
    "challenge_images_t,challenge_labels_t = get_img_label('challenge', 'train', num_classes=34)\n",
    "db_images,db_labels = get_img_label('db', 'all', num_classes=34)\n",
    "db_images_t,db_labels_t = get_img_label('db', 'train', num_classes=34)\n",
    "fn_images,fn_labels = get_img_label('fn', 'all', num_classes=34)\n",
    "fn_images_t,fn_labels_t = get_img_label('fn', 'train', num_classes=34)\n",
    "print(\"load data finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7371a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 512)\n",
      "(8446, 34)\n",
      "(762, 512)\n",
      "(762, 34)\n",
      "Epoch 1/70\n",
      "286/286 [==============================] - 2s 3ms/step - loss: 2.6231 - acc: 0.3274 - disc_loss: 1.3715 - disc_acc: 0.5563\n",
      "Epoch 2/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 1.9272 - acc: 0.5332 - disc_loss: 1.3644 - disc_acc: 0.5626\n",
      "Epoch 3/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 1.5195 - acc: 0.6095 - disc_loss: 1.3516 - disc_acc: 0.5796\n",
      "Epoch 4/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 1.2671 - acc: 0.6598 - disc_loss: 1.3459 - disc_acc: 0.5823\n",
      "Epoch 5/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 1.0807 - acc: 0.7079 - disc_loss: 1.3410 - disc_acc: 0.5844\n",
      "Epoch 6/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.9062 - acc: 0.7602 - disc_loss: 1.3359 - disc_acc: 0.5915\n",
      "Epoch 7/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.7775 - acc: 0.8010 - disc_loss: 1.3236 - disc_acc: 0.5981\n",
      "Epoch 8/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.6673 - acc: 0.8308 - disc_loss: 1.3172 - disc_acc: 0.6105\n",
      "Epoch 9/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.5797 - acc: 0.8574 - disc_loss: 1.3245 - disc_acc: 0.6007\n",
      "Epoch 10/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.5180 - acc: 0.8742 - disc_loss: 1.3149 - disc_acc: 0.6108\n",
      "Epoch 11/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.4598 - acc: 0.8877 - disc_loss: 1.3116 - disc_acc: 0.6106\n",
      "Epoch 12/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.4116 - acc: 0.9014 - disc_loss: 1.2998 - disc_acc: 0.6211\n",
      "Epoch 13/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.3801 - acc: 0.9125 - disc_loss: 1.2968 - disc_acc: 0.6257\n",
      "Epoch 14/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.3463 - acc: 0.9190 - disc_loss: 1.2974 - disc_acc: 0.6246\n",
      "Epoch 15/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.3270 - acc: 0.9238 - disc_loss: 1.2977 - disc_acc: 0.6249\n",
      "Epoch 16/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.2813 - acc: 0.9378 - disc_loss: 1.2960 - disc_acc: 0.6239\n",
      "Epoch 17/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.2643 - acc: 0.9400 - disc_loss: 1.2917 - disc_acc: 0.6238\n",
      "Epoch 18/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.2577 - acc: 0.9411 - disc_loss: 1.2916 - disc_acc: 0.6294\n",
      "Epoch 19/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.2292 - acc: 0.9481 - disc_loss: 1.2988 - disc_acc: 0.6182\n",
      "Epoch 20/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.2212 - acc: 0.9490 - disc_loss: 1.3007 - disc_acc: 0.6143\n",
      "Epoch 21/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.2083 - acc: 0.9524 - disc_loss: 1.2944 - disc_acc: 0.6278\n",
      "Epoch 22/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1990 - acc: 0.9566 - disc_loss: 1.2960 - disc_acc: 0.6213\n",
      "Epoch 23/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1840 - acc: 0.9579 - disc_loss: 1.3088 - disc_acc: 0.6152\n",
      "Epoch 24/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1758 - acc: 0.9593 - disc_loss: 1.3064 - disc_acc: 0.6175\n",
      "Epoch 25/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1629 - acc: 0.9621 - disc_loss: 1.3050 - disc_acc: 0.6181\n",
      "Epoch 26/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1577 - acc: 0.9642 - disc_loss: 1.3084 - disc_acc: 0.6115\n",
      "Epoch 27/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1494 - acc: 0.9668 - disc_loss: 1.3098 - disc_acc: 0.6094\n",
      "Epoch 28/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1463 - acc: 0.9668 - disc_loss: 1.3143 - disc_acc: 0.6080\n",
      "Epoch 29/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1349 - acc: 0.9684 - disc_loss: 1.3148 - disc_acc: 0.6108\n",
      "Epoch 30/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1233 - acc: 0.9718 - disc_loss: 1.3146 - disc_acc: 0.6035\n",
      "Epoch 31/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1227 - acc: 0.9711 - disc_loss: 1.3174 - disc_acc: 0.6079\n",
      "Epoch 32/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1231 - acc: 0.9718 - disc_loss: 1.3254 - disc_acc: 0.6009\n",
      "Epoch 33/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1241 - acc: 0.9709 - disc_loss: 1.3196 - disc_acc: 0.6035\n",
      "Epoch 34/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1066 - acc: 0.9753 - disc_loss: 1.3130 - disc_acc: 0.6095\n",
      "Epoch 35/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1033 - acc: 0.9754 - disc_loss: 1.3194 - disc_acc: 0.6047\n",
      "Epoch 36/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1004 - acc: 0.9797 - disc_loss: 1.3237 - disc_acc: 0.6010\n",
      "Epoch 37/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0934 - acc: 0.9791 - disc_loss: 1.3234 - disc_acc: 0.5996\n",
      "Epoch 38/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1037 - acc: 0.9757 - disc_loss: 1.3260 - disc_acc: 0.6019\n",
      "Epoch 39/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0908 - acc: 0.9791 - disc_loss: 1.3155 - disc_acc: 0.6122\n",
      "Epoch 40/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0904 - acc: 0.9791 - disc_loss: 1.3184 - disc_acc: 0.6020\n",
      "Epoch 41/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0905 - acc: 0.9792 - disc_loss: 1.3266 - disc_acc: 0.5969\n",
      "Epoch 42/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0940 - acc: 0.9791 - disc_loss: 1.3215 - disc_acc: 0.5993\n",
      "Epoch 43/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0954 - acc: 0.9763 - disc_loss: 1.3158 - disc_acc: 0.6080\n",
      "Epoch 44/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0807 - acc: 0.9833 - disc_loss: 1.3154 - disc_acc: 0.6061\n",
      "Epoch 45/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0971 - acc: 0.9762 - disc_loss: 1.3183 - disc_acc: 0.6031\n",
      "Epoch 46/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0664 - acc: 0.9857 - disc_loss: 1.3167 - disc_acc: 0.6017\n",
      "Epoch 47/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0659 - acc: 0.9859 - disc_loss: 1.3150 - disc_acc: 0.6057\n",
      "Epoch 48/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0684 - acc: 0.9849 - disc_loss: 1.3127 - disc_acc: 0.6105\n",
      "Epoch 49/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0657 - acc: 0.9863 - disc_loss: 1.3183 - disc_acc: 0.6022\n",
      "Epoch 50/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0796 - acc: 0.9821 - disc_loss: 1.3144 - disc_acc: 0.6029\n",
      "Epoch 51/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0734 - acc: 0.9827 - disc_loss: 1.3125 - disc_acc: 0.6051\n",
      "Epoch 52/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0689 - acc: 0.9844 - disc_loss: 1.3146 - disc_acc: 0.6070\n",
      "Epoch 53/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0727 - acc: 0.9822 - disc_loss: 1.3158 - disc_acc: 0.6027\n",
      "Epoch 54/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0633 - acc: 0.9855 - disc_loss: 1.3141 - disc_acc: 0.6058\n",
      "Epoch 55/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0591 - acc: 0.9862 - disc_loss: 1.3166 - disc_acc: 0.6006\n",
      "Epoch 56/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0538 - acc: 0.9870 - disc_loss: 1.3082 - disc_acc: 0.6058\n",
      "Epoch 57/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0637 - acc: 0.9852 - disc_loss: 1.3191 - disc_acc: 0.6003\n",
      "Epoch 58/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0522 - acc: 0.9881 - disc_loss: 1.3268 - disc_acc: 0.5930\n",
      "Epoch 59/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0565 - acc: 0.9859 - disc_loss: 1.3207 - disc_acc: 0.5976\n",
      "Epoch 60/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0510 - acc: 0.9897 - disc_loss: 1.3208 - disc_acc: 0.6026\n",
      "Epoch 61/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0733 - acc: 0.9817 - disc_loss: 1.3280 - disc_acc: 0.5930\n",
      "Epoch 62/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0630 - acc: 0.9850 - disc_loss: 1.3174 - disc_acc: 0.6000\n",
      "Epoch 63/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0742 - acc: 0.9795 - disc_loss: 1.3255 - disc_acc: 0.5922\n",
      "Epoch 64/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0948 - acc: 0.9731 - disc_loss: 1.3207 - disc_acc: 0.5943\n",
      "Epoch 65/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0529 - acc: 0.9885 - disc_loss: 1.3072 - disc_acc: 0.6072\n",
      "Epoch 66/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0609 - acc: 0.9835 - disc_loss: 1.3187 - disc_acc: 0.5995\n",
      "Epoch 67/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0397 - acc: 0.9919 - disc_loss: 1.3151 - disc_acc: 0.6046\n",
      "Epoch 68/70\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0474 - acc: 0.9885 - disc_loss: 1.3160 - disc_acc: 0.6017\n",
      "Epoch 69/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0518 - acc: 0.9860 - disc_loss: 1.3217 - disc_acc: 0.5953\n",
      "Epoch 70/70\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0498 - acc: 0.9885 - disc_loss: 1.3211 - disc_acc: 0.5940\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0410 - acc: 0.9897\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3612 - acc: 0.9368\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(base_labels))\n",
    "print(np.shape(weather_images_t))\n",
    "print(np.shape(weather_labels_t))\n",
    "weather_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "weather_model.fit(base_images, base_labels,weather_images_t,weather_labels_t, epochs=70,verbose=1,batch_size = 32)\n",
    "weather_model.score(base_images, base_labels)\n",
    "weather_model.score(weather_images, weather_labels)\n",
    "weather_model.save_weights(save_check_pt+ '/weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb4500f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 512)\n",
      "(8446, 34)\n",
      "(109, 512)\n",
      "(109, 34)\n",
      "Epoch 1/87\n",
      "266/266 [==============================] - 2s 4ms/step - loss: 2.6318 - acc: 0.3350 - disc_loss: 1.3893 - disc_acc: 0.5326\n",
      "Epoch 2/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 1.9398 - acc: 0.5163 - disc_loss: 1.3575 - disc_acc: 0.5721\n",
      "Epoch 3/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 1.4797 - acc: 0.6336 - disc_loss: 1.3432 - disc_acc: 0.5884\n",
      "Epoch 4/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 1.1908 - acc: 0.6871 - disc_loss: 1.3284 - disc_acc: 0.5943\n",
      "Epoch 5/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 1.0104 - acc: 0.7265 - disc_loss: 1.3140 - disc_acc: 0.6115\n",
      "Epoch 6/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.8728 - acc: 0.7678 - disc_loss: 1.2979 - disc_acc: 0.6163\n",
      "Epoch 7/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.7677 - acc: 0.7937 - disc_loss: 1.2940 - disc_acc: 0.6202\n",
      "Epoch 8/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.6739 - acc: 0.8275 - disc_loss: 1.2836 - disc_acc: 0.6276\n",
      "Epoch 9/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.6056 - acc: 0.8438 - disc_loss: 1.2631 - disc_acc: 0.6347\n",
      "Epoch 10/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.5559 - acc: 0.8594 - disc_loss: 1.2379 - disc_acc: 0.6499\n",
      "Epoch 11/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4926 - acc: 0.8770 - disc_loss: 1.2167 - disc_acc: 0.6708\n",
      "Epoch 12/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4452 - acc: 0.8901 - disc_loss: 1.2355 - disc_acc: 0.6548\n",
      "Epoch 13/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.4283 - acc: 0.8913 - disc_loss: 1.2284 - disc_acc: 0.6577\n",
      "Epoch 14/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3987 - acc: 0.9016 - disc_loss: 1.2256 - disc_acc: 0.6585\n",
      "Epoch 15/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3621 - acc: 0.9100 - disc_loss: 1.2291 - disc_acc: 0.6606\n",
      "Epoch 16/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.3249 - acc: 0.9210 - disc_loss: 1.2217 - disc_acc: 0.6628\n",
      "Epoch 17/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3186 - acc: 0.9227 - disc_loss: 1.2183 - disc_acc: 0.6583\n",
      "Epoch 18/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.2849 - acc: 0.9303 - disc_loss: 1.1877 - disc_acc: 0.6830\n",
      "Epoch 19/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.2674 - acc: 0.9364 - disc_loss: 1.2032 - disc_acc: 0.6663\n",
      "Epoch 20/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.2635 - acc: 0.9366 - disc_loss: 1.2074 - disc_acc: 0.6680\n",
      "Epoch 21/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.2601 - acc: 0.9373 - disc_loss: 1.2120 - disc_acc: 0.6601\n",
      "Epoch 22/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.2324 - acc: 0.9450 - disc_loss: 1.2316 - disc_acc: 0.6540\n",
      "Epoch 23/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.2203 - acc: 0.9479 - disc_loss: 1.2325 - disc_acc: 0.6479\n",
      "Epoch 24/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.2088 - acc: 0.9498 - disc_loss: 1.2171 - disc_acc: 0.6632\n",
      "Epoch 25/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1950 - acc: 0.9552 - disc_loss: 1.2312 - disc_acc: 0.6561\n",
      "Epoch 26/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1743 - acc: 0.9591 - disc_loss: 1.2132 - disc_acc: 0.6614\n",
      "Epoch 27/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1801 - acc: 0.9575 - disc_loss: 1.2345 - disc_acc: 0.6485\n",
      "Epoch 28/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1748 - acc: 0.9586 - disc_loss: 1.2501 - disc_acc: 0.6475\n",
      "Epoch 29/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1693 - acc: 0.9599 - disc_loss: 1.2473 - disc_acc: 0.6443\n",
      "Epoch 30/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1713 - acc: 0.9597 - disc_loss: 1.2338 - disc_acc: 0.6570\n",
      "Epoch 31/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1610 - acc: 0.9620 - disc_loss: 1.2479 - disc_acc: 0.6425\n",
      "Epoch 32/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1616 - acc: 0.9604 - disc_loss: 1.2640 - disc_acc: 0.6289\n",
      "Epoch 33/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1525 - acc: 0.9640 - disc_loss: 1.2271 - disc_acc: 0.6521\n",
      "Epoch 34/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1381 - acc: 0.9687 - disc_loss: 1.2253 - disc_acc: 0.6564\n",
      "Epoch 35/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1359 - acc: 0.9654 - disc_loss: 1.2304 - disc_acc: 0.6492\n",
      "Epoch 36/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1255 - acc: 0.9701 - disc_loss: 1.2411 - disc_acc: 0.6370\n",
      "Epoch 37/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1268 - acc: 0.9697 - disc_loss: 1.2235 - disc_acc: 0.6570\n",
      "Epoch 38/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1219 - acc: 0.9705 - disc_loss: 1.2526 - disc_acc: 0.6454\n",
      "Epoch 39/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0995 - acc: 0.9787 - disc_loss: 1.2578 - disc_acc: 0.6425\n",
      "Epoch 40/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1083 - acc: 0.9735 - disc_loss: 1.2612 - disc_acc: 0.6375\n",
      "Epoch 41/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1149 - acc: 0.9704 - disc_loss: 1.2473 - disc_acc: 0.6431\n",
      "Epoch 42/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1171 - acc: 0.9712 - disc_loss: 1.2466 - disc_acc: 0.6380\n",
      "Epoch 43/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0978 - acc: 0.9761 - disc_loss: 1.2542 - disc_acc: 0.6397\n",
      "Epoch 44/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1100 - acc: 0.9733 - disc_loss: 1.2649 - disc_acc: 0.6319\n",
      "Epoch 45/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1008 - acc: 0.9744 - disc_loss: 1.2554 - disc_acc: 0.6310\n",
      "Epoch 46/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1108 - acc: 0.9718 - disc_loss: 1.2353 - disc_acc: 0.6509\n",
      "Epoch 47/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1017 - acc: 0.9761 - disc_loss: 1.2203 - disc_acc: 0.6514\n",
      "Epoch 48/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0794 - acc: 0.9805 - disc_loss: 1.2574 - disc_acc: 0.6308\n",
      "Epoch 49/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1020 - acc: 0.9732 - disc_loss: 1.2546 - disc_acc: 0.6303\n",
      "Epoch 50/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0833 - acc: 0.9805 - disc_loss: 1.2422 - disc_acc: 0.6479\n",
      "Epoch 51/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0887 - acc: 0.9779 - disc_loss: 1.2371 - disc_acc: 0.6457\n",
      "Epoch 52/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0672 - acc: 0.9861 - disc_loss: 1.2679 - disc_acc: 0.6288\n",
      "Epoch 53/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0637 - acc: 0.9846 - disc_loss: 1.2771 - disc_acc: 0.6167\n",
      "Epoch 54/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0720 - acc: 0.9835 - disc_loss: 1.2427 - disc_acc: 0.6413\n",
      "Epoch 55/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0646 - acc: 0.9872 - disc_loss: 1.2740 - disc_acc: 0.6283\n",
      "Epoch 56/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0772 - acc: 0.9812 - disc_loss: 1.2495 - disc_acc: 0.6425\n",
      "Epoch 57/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0655 - acc: 0.9858 - disc_loss: 1.2547 - disc_acc: 0.6361\n",
      "Epoch 58/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0682 - acc: 0.9832 - disc_loss: 1.2695 - disc_acc: 0.6333\n",
      "Epoch 59/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0753 - acc: 0.9822 - disc_loss: 1.2601 - disc_acc: 0.6357\n",
      "Epoch 60/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.1155 - acc: 0.9680 - disc_loss: 1.2159 - disc_acc: 0.6617\n",
      "Epoch 61/87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0788 - acc: 0.9802 - disc_loss: 1.2349 - disc_acc: 0.6505\n",
      "Epoch 62/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0662 - acc: 0.9832 - disc_loss: 1.2598 - disc_acc: 0.6326\n",
      "Epoch 63/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0681 - acc: 0.9834 - disc_loss: 1.2360 - disc_acc: 0.6409\n",
      "Epoch 64/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0580 - acc: 0.9864 - disc_loss: 1.2568 - disc_acc: 0.6235\n",
      "Epoch 65/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0688 - acc: 0.9832 - disc_loss: 1.2398 - disc_acc: 0.6394\n",
      "Epoch 66/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0675 - acc: 0.9825 - disc_loss: 1.2439 - disc_acc: 0.6405\n",
      "Epoch 67/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0773 - acc: 0.9780 - disc_loss: 1.2329 - disc_acc: 0.6504\n",
      "Epoch 68/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0640 - acc: 0.9837 - disc_loss: 1.2422 - disc_acc: 0.6414\n",
      "Epoch 69/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0718 - acc: 0.9811 - disc_loss: 1.2400 - disc_acc: 0.6510\n",
      "Epoch 70/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0737 - acc: 0.9806 - disc_loss: 1.2215 - disc_acc: 0.6537\n",
      "Epoch 71/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0596 - acc: 0.9859 - disc_loss: 1.2197 - disc_acc: 0.6569\n",
      "Epoch 72/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0613 - acc: 0.9854 - disc_loss: 1.2486 - disc_acc: 0.6366\n",
      "Epoch 73/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0524 - acc: 0.9875 - disc_loss: 1.2320 - disc_acc: 0.6503\n",
      "Epoch 74/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0608 - acc: 0.9861 - disc_loss: 1.2391 - disc_acc: 0.6417\n",
      "Epoch 75/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0855 - acc: 0.9765 - disc_loss: 1.2213 - disc_acc: 0.6576\n",
      "Epoch 76/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0707 - acc: 0.9827 - disc_loss: 1.2366 - disc_acc: 0.6474\n",
      "Epoch 77/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0604 - acc: 0.9858 - disc_loss: 1.2372 - disc_acc: 0.6448\n",
      "Epoch 78/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0460 - acc: 0.9906 - disc_loss: 1.2800 - disc_acc: 0.6259\n",
      "Epoch 79/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0641 - acc: 0.9831 - disc_loss: 1.2465 - disc_acc: 0.6457\n",
      "Epoch 80/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0615 - acc: 0.9849 - disc_loss: 1.2405 - disc_acc: 0.6455\n",
      "Epoch 81/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0460 - acc: 0.9898 - disc_loss: 1.2502 - disc_acc: 0.6335\n",
      "Epoch 82/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0469 - acc: 0.9892 - disc_loss: 1.2458 - disc_acc: 0.6447\n",
      "Epoch 83/87\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0425 - acc: 0.9911 - disc_loss: 1.2586 - disc_acc: 0.6391\n",
      "Epoch 84/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0513 - acc: 0.9886 - disc_loss: 1.2862 - disc_acc: 0.6125\n",
      "Epoch 85/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0852 - acc: 0.9765 - disc_loss: 1.2465 - disc_acc: 0.6378\n",
      "Epoch 86/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0604 - acc: 0.9852 - disc_loss: 1.2276 - disc_acc: 0.6490\n",
      "Epoch 87/87\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.0528 - acc: 0.9868 - disc_loss: 1.2479 - disc_acc: 0.6329\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0395 - acc: 0.9910\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0284 - acc: 0.8631\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(base_labels))\n",
    "print(np.shape(challenge_images_t))\n",
    "print(np.shape(challenge_labels_t))\n",
    "challenge_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "challenge_model.fit(base_images, base_labels,challenge_images_t,challenge_labels_t, epochs=87,verbose=1,batch_size = 32)\n",
    "challenge_model.score(base_images, base_labels)\n",
    "challenge_model.score(challenge_images, challenge_labels)\n",
    "challenge_model.save_weights(save_check_pt+ '/challenge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14fa698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 512)\n",
      "(8446, 34)\n",
      "(373, 512)\n",
      "(373, 34)\n",
      "Epoch 1/88\n",
      "269/269 [==============================] - 2s 4ms/step - loss: 2.6060 - acc: 0.3292 - disc_loss: 1.3746 - disc_acc: 0.5535\n",
      "Epoch 2/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 1.9326 - acc: 0.5337 - disc_loss: 1.3459 - disc_acc: 0.5806\n",
      "Epoch 3/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 1.4952 - acc: 0.6280 - disc_loss: 1.3183 - disc_acc: 0.6167\n",
      "Epoch 4/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 1.2306 - acc: 0.6769 - disc_loss: 1.3383 - disc_acc: 0.5783\n",
      "Epoch 5/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 1.0684 - acc: 0.7100 - disc_loss: 1.2981 - disc_acc: 0.6220\n",
      "Epoch 6/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.8885 - acc: 0.7554 - disc_loss: 1.3029 - disc_acc: 0.6116\n",
      "Epoch 7/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.7642 - acc: 0.8007 - disc_loss: 1.2995 - disc_acc: 0.6235\n",
      "Epoch 8/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.6759 - acc: 0.8312 - disc_loss: 1.3225 - disc_acc: 0.6002\n",
      "Epoch 9/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.6109 - acc: 0.8497 - disc_loss: 1.3145 - disc_acc: 0.6033\n",
      "Epoch 10/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.5337 - acc: 0.8668 - disc_loss: 1.3085 - disc_acc: 0.6111\n",
      "Epoch 11/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.5063 - acc: 0.8732 - disc_loss: 1.3024 - disc_acc: 0.6145\n",
      "Epoch 12/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.4525 - acc: 0.8861 - disc_loss: 1.2947 - disc_acc: 0.6285\n",
      "Epoch 13/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.4190 - acc: 0.8979 - disc_loss: 1.3214 - disc_acc: 0.5972\n",
      "Epoch 14/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.3833 - acc: 0.9023 - disc_loss: 1.3092 - disc_acc: 0.6138\n",
      "Epoch 15/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.3509 - acc: 0.9120 - disc_loss: 1.3128 - disc_acc: 0.6031\n",
      "Epoch 16/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.3298 - acc: 0.9191 - disc_loss: 1.3099 - disc_acc: 0.6119\n",
      "Epoch 17/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.3123 - acc: 0.9231 - disc_loss: 1.3061 - disc_acc: 0.6137\n",
      "Epoch 18/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.2921 - acc: 0.9299 - disc_loss: 1.3070 - disc_acc: 0.6104\n",
      "Epoch 19/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.2797 - acc: 0.9296 - disc_loss: 1.3108 - disc_acc: 0.6089\n",
      "Epoch 20/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.2623 - acc: 0.9392 - disc_loss: 1.3127 - disc_acc: 0.6073\n",
      "Epoch 21/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.2477 - acc: 0.9429 - disc_loss: 1.3050 - disc_acc: 0.6080\n",
      "Epoch 22/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.2250 - acc: 0.9451 - disc_loss: 1.3056 - disc_acc: 0.6077\n",
      "Epoch 23/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.2097 - acc: 0.9513 - disc_loss: 1.3151 - disc_acc: 0.5990\n",
      "Epoch 24/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.2035 - acc: 0.9520 - disc_loss: 1.3139 - disc_acc: 0.6067\n",
      "Epoch 25/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1993 - acc: 0.9494 - disc_loss: 1.3160 - disc_acc: 0.5975\n",
      "Epoch 26/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1843 - acc: 0.9554 - disc_loss: 1.3138 - disc_acc: 0.6004\n",
      "Epoch 27/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1898 - acc: 0.9527 - disc_loss: 1.3063 - disc_acc: 0.6084\n",
      "Epoch 28/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1926 - acc: 0.9542 - disc_loss: 1.3229 - disc_acc: 0.5972\n",
      "Epoch 29/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1673 - acc: 0.9585 - disc_loss: 1.3053 - disc_acc: 0.6117\n",
      "Epoch 30/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1520 - acc: 0.9656 - disc_loss: 1.3191 - disc_acc: 0.5999\n",
      "Epoch 31/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1434 - acc: 0.9657 - disc_loss: 1.3097 - disc_acc: 0.6050\n",
      "Epoch 32/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1500 - acc: 0.9651 - disc_loss: 1.2926 - disc_acc: 0.6190\n",
      "Epoch 33/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1361 - acc: 0.9697 - disc_loss: 1.3141 - disc_acc: 0.6089\n",
      "Epoch 34/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1182 - acc: 0.9735 - disc_loss: 1.3171 - disc_acc: 0.6035\n",
      "Epoch 35/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1118 - acc: 0.9737 - disc_loss: 1.3260 - disc_acc: 0.5931\n",
      "Epoch 36/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1123 - acc: 0.9754 - disc_loss: 1.3160 - disc_acc: 0.6067\n",
      "Epoch 37/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1306 - acc: 0.9678 - disc_loss: 1.3189 - disc_acc: 0.6097\n",
      "Epoch 38/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1101 - acc: 0.9758 - disc_loss: 1.3296 - disc_acc: 0.5910\n",
      "Epoch 39/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0996 - acc: 0.9752 - disc_loss: 1.3251 - disc_acc: 0.5957\n",
      "Epoch 40/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1124 - acc: 0.9723 - disc_loss: 1.3169 - disc_acc: 0.6031\n",
      "Epoch 41/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1193 - acc: 0.9690 - disc_loss: 1.3061 - disc_acc: 0.6086\n",
      "Epoch 42/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0943 - acc: 0.9760 - disc_loss: 1.3307 - disc_acc: 0.5838\n",
      "Epoch 43/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0816 - acc: 0.9816 - disc_loss: 1.3155 - disc_acc: 0.5981\n",
      "Epoch 44/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0977 - acc: 0.9753 - disc_loss: 1.3253 - disc_acc: 0.5963\n",
      "Epoch 45/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0914 - acc: 0.9780 - disc_loss: 1.3152 - disc_acc: 0.6181\n",
      "Epoch 46/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1132 - acc: 0.9697 - disc_loss: 1.3178 - disc_acc: 0.5974\n",
      "Epoch 47/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0987 - acc: 0.9739 - disc_loss: 1.3162 - disc_acc: 0.6155\n",
      "Epoch 48/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0871 - acc: 0.9782 - disc_loss: 1.3261 - disc_acc: 0.5925\n",
      "Epoch 49/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0876 - acc: 0.9775 - disc_loss: 1.3090 - disc_acc: 0.6092\n",
      "Epoch 50/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0697 - acc: 0.9843 - disc_loss: 1.3229 - disc_acc: 0.5986\n",
      "Epoch 51/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0806 - acc: 0.9808 - disc_loss: 1.3245 - disc_acc: 0.5885\n",
      "Epoch 52/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0788 - acc: 0.9811 - disc_loss: 1.3261 - disc_acc: 0.5869\n",
      "Epoch 53/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0772 - acc: 0.9810 - disc_loss: 1.3294 - disc_acc: 0.5856\n",
      "Epoch 54/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0915 - acc: 0.9755 - disc_loss: 1.3317 - disc_acc: 0.5854\n",
      "Epoch 55/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0852 - acc: 0.9795 - disc_loss: 1.3259 - disc_acc: 0.5943\n",
      "Epoch 56/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0723 - acc: 0.9830 - disc_loss: 1.3266 - disc_acc: 0.6003\n",
      "Epoch 57/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0825 - acc: 0.9796 - disc_loss: 1.3195 - disc_acc: 0.5950\n",
      "Epoch 58/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0658 - acc: 0.9844 - disc_loss: 1.3228 - disc_acc: 0.5951\n",
      "Epoch 59/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0586 - acc: 0.9871 - disc_loss: 1.3257 - disc_acc: 0.5912\n",
      "Epoch 60/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0694 - acc: 0.9825 - disc_loss: 1.3264 - disc_acc: 0.5937\n",
      "Epoch 61/88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0545 - acc: 0.9864 - disc_loss: 1.3196 - disc_acc: 0.5964\n",
      "Epoch 62/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0779 - acc: 0.9788 - disc_loss: 1.3193 - disc_acc: 0.5961\n",
      "Epoch 63/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0842 - acc: 0.9762 - disc_loss: 1.3161 - disc_acc: 0.6095\n",
      "Epoch 64/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0515 - acc: 0.9878 - disc_loss: 1.3068 - disc_acc: 0.6068\n",
      "Epoch 65/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0533 - acc: 0.9873 - disc_loss: 1.3219 - disc_acc: 0.5972\n",
      "Epoch 66/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0688 - acc: 0.9801 - disc_loss: 1.3161 - disc_acc: 0.6016\n",
      "Epoch 67/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0514 - acc: 0.9872 - disc_loss: 1.3209 - disc_acc: 0.6005\n",
      "Epoch 68/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0528 - acc: 0.9874 - disc_loss: 1.3271 - disc_acc: 0.6045\n",
      "Epoch 69/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0606 - acc: 0.9847 - disc_loss: 1.3188 - disc_acc: 0.6073\n",
      "Epoch 70/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0594 - acc: 0.9847 - disc_loss: 1.3215 - disc_acc: 0.6008\n",
      "Epoch 71/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0580 - acc: 0.9854 - disc_loss: 1.3252 - disc_acc: 0.5982\n",
      "Epoch 72/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0668 - acc: 0.9826 - disc_loss: 1.3182 - disc_acc: 0.6067\n",
      "Epoch 73/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0731 - acc: 0.9795 - disc_loss: 1.3194 - disc_acc: 0.5956\n",
      "Epoch 74/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0602 - acc: 0.9847 - disc_loss: 1.3137 - disc_acc: 0.6020\n",
      "Epoch 75/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0427 - acc: 0.9892 - disc_loss: 1.3246 - disc_acc: 0.5916\n",
      "Epoch 76/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0417 - acc: 0.9896 - disc_loss: 1.3271 - disc_acc: 0.5916\n",
      "Epoch 77/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0410 - acc: 0.9892 - disc_loss: 1.3136 - disc_acc: 0.6005\n",
      "Epoch 78/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0413 - acc: 0.9892 - disc_loss: 1.3282 - disc_acc: 0.5952\n",
      "Epoch 79/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0376 - acc: 0.9917 - disc_loss: 1.3202 - disc_acc: 0.6010\n",
      "Epoch 80/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0518 - acc: 0.9852 - disc_loss: 1.3320 - disc_acc: 0.5862\n",
      "Epoch 81/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0887 - acc: 0.9738 - disc_loss: 1.3183 - disc_acc: 0.5976\n",
      "Epoch 82/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0855 - acc: 0.9745 - disc_loss: 1.2995 - disc_acc: 0.6175\n",
      "Epoch 83/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0530 - acc: 0.9854 - disc_loss: 1.3078 - disc_acc: 0.6120\n",
      "Epoch 84/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0594 - acc: 0.9837 - disc_loss: 1.3044 - disc_acc: 0.6181\n",
      "Epoch 85/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1088 - acc: 0.9676 - disc_loss: 1.2917 - disc_acc: 0.6184\n",
      "Epoch 86/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0510 - acc: 0.9879 - disc_loss: 1.2871 - disc_acc: 0.6204\n",
      "Epoch 87/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0356 - acc: 0.9913 - disc_loss: 1.2903 - disc_acc: 0.6157\n",
      "Epoch 88/88\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0293 - acc: 0.9929 - disc_loss: 1.2991 - disc_acc: 0.6055\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BD9F11B280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0486 - acc: 0.9867\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BD9F11B280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0769 - acc: 0.8422\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(base_labels))\n",
    "print(np.shape(db_images_t))\n",
    "print(np.shape(db_labels_t))\n",
    "db_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "db_model.fit(base_images, base_labels,db_images_t,db_labels_t, epochs=88,verbose=1,batch_size = 32)\n",
    "db_model.score(base_images, base_labels)\n",
    "db_model.score(db_images, db_labels)\n",
    "db_model.save_weights(save_check_pt+ '/db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29be5160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 512)\n",
      "(8446, 34)\n",
      "(48, 512)\n",
      "(48, 34)\n",
      "Epoch 1/87\n",
      "264/264 [==============================] - 2s 5ms/step - loss: 2.5996 - acc: 0.3267 - disc_loss: 1.3878 - disc_acc: 0.5377\n",
      "Epoch 2/87\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 1.8889 - acc: 0.5469 - disc_loss: 1.3367 - disc_acc: 0.5966\n",
      "Epoch 3/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 1.4694 - acc: 0.6390 - disc_loss: 1.3185 - disc_acc: 0.6108\n",
      "Epoch 4/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 1.1984 - acc: 0.6877 - disc_loss: 1.3036 - disc_acc: 0.6173\n",
      "Epoch 5/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.9998 - acc: 0.7350 - disc_loss: 1.2526 - disc_acc: 0.6481\n",
      "Epoch 6/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.8570 - acc: 0.7798 - disc_loss: 1.2471 - disc_acc: 0.6544\n",
      "Epoch 7/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.7293 - acc: 0.8087 - disc_loss: 1.2175 - disc_acc: 0.6672\n",
      "Epoch 8/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.6654 - acc: 0.8317 - disc_loss: 1.2321 - disc_acc: 0.6638\n",
      "Epoch 9/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.5955 - acc: 0.8469 - disc_loss: 1.2100 - disc_acc: 0.6794\n",
      "Epoch 10/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.5404 - acc: 0.8604 - disc_loss: 1.2236 - disc_acc: 0.6743\n",
      "Epoch 11/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.4897 - acc: 0.8749 - disc_loss: 1.1972 - disc_acc: 0.6835\n",
      "Epoch 12/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.4472 - acc: 0.8878 - disc_loss: 1.1979 - disc_acc: 0.6794\n",
      "Epoch 13/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.4192 - acc: 0.8969 - disc_loss: 1.2032 - disc_acc: 0.6734\n",
      "Epoch 14/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.4012 - acc: 0.9016 - disc_loss: 1.1970 - disc_acc: 0.6816\n",
      "Epoch 15/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.3790 - acc: 0.9077 - disc_loss: 1.2061 - disc_acc: 0.6725\n",
      "Epoch 16/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.3391 - acc: 0.9164 - disc_loss: 1.2067 - disc_acc: 0.6697\n",
      "Epoch 17/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.3090 - acc: 0.9252 - disc_loss: 1.1827 - disc_acc: 0.6799\n",
      "Epoch 18/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.2867 - acc: 0.9281 - disc_loss: 1.1916 - disc_acc: 0.6763\n",
      "Epoch 19/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.2718 - acc: 0.9350 - disc_loss: 1.1834 - disc_acc: 0.6728\n",
      "Epoch 20/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.2621 - acc: 0.9358 - disc_loss: 1.1860 - disc_acc: 0.6837\n",
      "Epoch 21/87\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.2417 - acc: 0.9440 - disc_loss: 1.1749 - disc_acc: 0.6913\n",
      "Epoch 22/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.2284 - acc: 0.9469 - disc_loss: 1.1577 - disc_acc: 0.6955\n",
      "Epoch 23/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.2117 - acc: 0.9534 - disc_loss: 1.1762 - disc_acc: 0.6715\n",
      "Epoch 24/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.2101 - acc: 0.9510 - disc_loss: 1.1853 - disc_acc: 0.6652\n",
      "Epoch 25/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.2022 - acc: 0.9523 - disc_loss: 1.1971 - disc_acc: 0.6585\n",
      "Epoch 26/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1990 - acc: 0.9527 - disc_loss: 1.1619 - disc_acc: 0.6831\n",
      "Epoch 27/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1815 - acc: 0.9577 - disc_loss: 1.1531 - disc_acc: 0.6906\n",
      "Epoch 28/87\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.1823 - acc: 0.9562 - disc_loss: 1.1934 - disc_acc: 0.6758\n",
      "Epoch 29/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1650 - acc: 0.9605 - disc_loss: 1.2105 - disc_acc: 0.6626\n",
      "Epoch 30/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1616 - acc: 0.9643 - disc_loss: 1.1979 - disc_acc: 0.6663\n",
      "Epoch 31/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1530 - acc: 0.9653 - disc_loss: 1.1938 - disc_acc: 0.6740\n",
      "Epoch 32/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1573 - acc: 0.9626 - disc_loss: 1.1748 - disc_acc: 0.6808\n",
      "Epoch 33/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1407 - acc: 0.9661 - disc_loss: 1.2167 - disc_acc: 0.6559\n",
      "Epoch 34/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1268 - acc: 0.9701 - disc_loss: 1.1752 - disc_acc: 0.6758\n",
      "Epoch 35/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1226 - acc: 0.9719 - disc_loss: 1.1761 - disc_acc: 0.6700\n",
      "Epoch 36/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1264 - acc: 0.9724 - disc_loss: 1.1916 - disc_acc: 0.6666\n",
      "Epoch 37/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1212 - acc: 0.9701 - disc_loss: 1.2059 - disc_acc: 0.6487\n",
      "Epoch 38/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1244 - acc: 0.9708 - disc_loss: 1.1642 - disc_acc: 0.6808\n",
      "Epoch 39/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1200 - acc: 0.9716 - disc_loss: 1.1667 - disc_acc: 0.6905\n",
      "Epoch 40/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1105 - acc: 0.9729 - disc_loss: 1.1667 - disc_acc: 0.6841\n",
      "Epoch 41/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1134 - acc: 0.9725 - disc_loss: 1.1745 - disc_acc: 0.6680\n",
      "Epoch 42/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1165 - acc: 0.9729 - disc_loss: 1.1959 - disc_acc: 0.6806\n",
      "Epoch 43/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1237 - acc: 0.9699 - disc_loss: 1.1942 - disc_acc: 0.6715\n",
      "Epoch 44/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1118 - acc: 0.9725 - disc_loss: 1.1839 - disc_acc: 0.6725\n",
      "Epoch 45/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0903 - acc: 0.9801 - disc_loss: 1.1967 - disc_acc: 0.6636\n",
      "Epoch 46/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0853 - acc: 0.9807 - disc_loss: 1.1964 - disc_acc: 0.6694\n",
      "Epoch 47/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0795 - acc: 0.9821 - disc_loss: 1.1701 - disc_acc: 0.6846\n",
      "Epoch 48/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0740 - acc: 0.9820 - disc_loss: 1.2425 - disc_acc: 0.6471\n",
      "Epoch 49/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0794 - acc: 0.9824 - disc_loss: 1.2369 - disc_acc: 0.6334\n",
      "Epoch 50/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0788 - acc: 0.9822 - disc_loss: 1.2300 - disc_acc: 0.6453\n",
      "Epoch 51/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0813 - acc: 0.9809 - disc_loss: 1.2306 - disc_acc: 0.6442\n",
      "Epoch 52/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0875 - acc: 0.9789 - disc_loss: 1.2068 - disc_acc: 0.6624\n",
      "Epoch 53/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0807 - acc: 0.9799 - disc_loss: 1.2206 - disc_acc: 0.6548\n",
      "Epoch 54/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0743 - acc: 0.9822 - disc_loss: 1.2238 - disc_acc: 0.6505\n",
      "Epoch 55/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0819 - acc: 0.9801 - disc_loss: 1.2292 - disc_acc: 0.6545\n",
      "Epoch 56/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0726 - acc: 0.9838 - disc_loss: 1.2283 - disc_acc: 0.6488\n",
      "Epoch 57/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0865 - acc: 0.9783 - disc_loss: 1.2172 - disc_acc: 0.6514\n",
      "Epoch 58/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0679 - acc: 0.9835 - disc_loss: 1.1870 - disc_acc: 0.6679\n",
      "Epoch 59/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0597 - acc: 0.9872 - disc_loss: 1.2187 - disc_acc: 0.6585\n",
      "Epoch 60/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0612 - acc: 0.9862 - disc_loss: 1.2175 - disc_acc: 0.6591\n",
      "Epoch 61/87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0792 - acc: 0.9790 - disc_loss: 1.2103 - disc_acc: 0.6700\n",
      "Epoch 62/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0845 - acc: 0.9786 - disc_loss: 1.2084 - disc_acc: 0.6600\n",
      "Epoch 63/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0902 - acc: 0.9742 - disc_loss: 1.2026 - disc_acc: 0.6669\n",
      "Epoch 64/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0827 - acc: 0.9783 - disc_loss: 1.2217 - disc_acc: 0.6551\n",
      "Epoch 65/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0666 - acc: 0.9825 - disc_loss: 1.2081 - disc_acc: 0.6590\n",
      "Epoch 66/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0699 - acc: 0.9825 - disc_loss: 1.1961 - disc_acc: 0.6775\n",
      "Epoch 67/87\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0726 - acc: 0.9798 - disc_loss: 1.1759 - disc_acc: 0.6705\n",
      "Epoch 68/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0697 - acc: 0.9820 - disc_loss: 1.1886 - disc_acc: 0.6674\n",
      "Epoch 69/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0546 - acc: 0.9873 - disc_loss: 1.2101 - disc_acc: 0.6570\n",
      "Epoch 70/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0591 - acc: 0.9862 - disc_loss: 1.2028 - disc_acc: 0.6672\n",
      "Epoch 71/87\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0592 - acc: 0.9856 - disc_loss: 1.2033 - disc_acc: 0.6580\n",
      "Epoch 72/87\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0803 - acc: 0.9793 - disc_loss: 1.2036 - disc_acc: 0.6542\n",
      "Epoch 73/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0697 - acc: 0.9811 - disc_loss: 1.1759 - disc_acc: 0.6792\n",
      "Epoch 74/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0695 - acc: 0.9833 - disc_loss: 1.1854 - disc_acc: 0.6631\n",
      "Epoch 75/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0667 - acc: 0.9828 - disc_loss: 1.1928 - disc_acc: 0.6633\n",
      "Epoch 76/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0726 - acc: 0.9813 - disc_loss: 1.2066 - disc_acc: 0.6550\n",
      "Epoch 77/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0697 - acc: 0.9814 - disc_loss: 1.1980 - disc_acc: 0.6556\n",
      "Epoch 78/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0604 - acc: 0.9859 - disc_loss: 1.2148 - disc_acc: 0.6458\n",
      "Epoch 79/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0499 - acc: 0.9872 - disc_loss: 1.2202 - disc_acc: 0.6525\n",
      "Epoch 80/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0597 - acc: 0.9834 - disc_loss: 1.1729 - disc_acc: 0.6871\n",
      "Epoch 81/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0689 - acc: 0.9821 - disc_loss: 1.1716 - disc_acc: 0.6933\n",
      "Epoch 82/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0709 - acc: 0.9808 - disc_loss: 1.1919 - disc_acc: 0.6588\n",
      "Epoch 83/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0526 - acc: 0.9866 - disc_loss: 1.2122 - disc_acc: 0.6644\n",
      "Epoch 84/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0571 - acc: 0.9865 - disc_loss: 1.2080 - disc_acc: 0.6583\n",
      "Epoch 85/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0734 - acc: 0.9805 - disc_loss: 1.2251 - disc_acc: 0.6494\n",
      "Epoch 86/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0590 - acc: 0.9845 - disc_loss: 1.2000 - disc_acc: 0.6562\n",
      "Epoch 87/87\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0544 - acc: 0.9858 - disc_loss: 1.1841 - disc_acc: 0.6528\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0387 - acc: 0.9911\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1455 - acc: 0.9671\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(base_labels))\n",
    "print(np.shape(fn_images_t))\n",
    "print(np.shape(fn_labels_t))\n",
    "fn_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "fn_model.fit(base_images, base_labels,fn_images_t,fn_labels_t, epochs=87,verbose=1,batch_size = 32)\n",
    "fn_model.score(base_images, base_labels)\n",
    "fn_model.score(fn_images, fn_labels)\n",
    "fn_model.save_weights(save_check_pt+ '/fn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
