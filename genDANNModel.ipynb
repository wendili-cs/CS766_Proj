{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2410689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 32, 16, 3)\n",
      "load data finished!\n"
     ]
    }
   ],
   "source": [
    "import  os, glob\n",
    "import  random, csv\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import adapt\n",
    "from adapt.feature_based import DANN\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape,Conv2D,MaxPool2D,Flatten,Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# The path of the datasets, use dict format\n",
    "dataset_path = {\"base\": \"dataset/ccpd/splitted_plates_base\", \n",
    "                \"challenge\":\"dataset/ccpd/splitted_plates_challenge\",\n",
    "               \"db\":\"dataset/ccpd/splitted_plates_db\",\n",
    "               \"fn\":\"dataset/ccpd/splitted_plates_fn\",\n",
    "               \"weather\":\"dataset/ccpd/splitted_plates_weather\"}\n",
    "# The path of the saving model check points\n",
    "save_check_pt = './checkpoints_DANN'\n",
    "\n",
    "def load_csv(root, filename, name2label):\n",
    "    # From csv file return images dir,labels list\n",
    "    if not os.path.exists(os.path.join(root, filename)):\n",
    "        images = []\n",
    "        for name in name2label.keys(): \n",
    "            images += glob.glob(os.path.join(root, name, '*.png'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpg'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpeg'))\n",
    "        #print(len(images), images)\n",
    "        random.shuffle(images) # shuffle images\n",
    "        with open(os.path.join(root, filename), mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for img in images:  \n",
    "                name = img.split(os.sep)[-2]\n",
    "                label = name2label[name]\n",
    "                writer.writerow([img, label])\n",
    "            print('written into csv file:', filename)\n",
    "    # read existed csv\n",
    "    images, labels = [], []\n",
    "    with open(os.path.join(root, filename)) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            img, label = row\n",
    "            label = int(label)\n",
    "            images.append(img)\n",
    "            labels.append(label) \n",
    "    # return img dir and label\n",
    "    return images, labels\n",
    "\n",
    "def load_ccpd(root, mode='train'):\n",
    "    name2label = {}  # \"sq...\":0\n",
    "    # iterate sub dir, sort, while keep mapping\n",
    "    for name in sorted(os.listdir(os.path.join(root))):\n",
    "        # skip non file folder\n",
    "        if not os.path.isdir(os.path.join(root, name)):\n",
    "            continue\n",
    "        # give each category a number\n",
    "        name2label[name] = len(name2label.keys())\n",
    "    images, labels = load_csv(root, 'images.csv', name2label)\n",
    "    if mode == 'train':  # 20%\n",
    "        images = images[:int(0.2 * len(images))]\n",
    "        labels = labels[:int(0.2 * len(labels))]\n",
    "    elif mode == 'val':  # 20% = 60%->80%\n",
    "        images = images[int(0.6 * len(images)):int(0.8 * len(images))]\n",
    "        labels = labels[int(0.6 * len(labels)):int(0.8 * len(labels))]\n",
    "    else:  # all\n",
    "        images = images\n",
    "        labels = labels\n",
    "    return images, labels, name2label\n",
    "\n",
    "def readCcpdImg(images_dir):\n",
    "    X = []\n",
    "    for img_dir in images_dir:\n",
    "        img = cv2.imread(img_dir)\n",
    "        img = cv2.resize(img,(16,32))\n",
    "        X.append(img)\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "# def readCcpdImg(images_dir):\n",
    "#     X = []\n",
    "#     for img_dir in images_dir:\n",
    "#         img = Image.open(img_dir)\n",
    "#         img = img.convert('L') # conver to grayscale images\n",
    "#         img = img.resize([16, 32])\n",
    "#         img_np = np.asarray(img)\n",
    "#         X.append(img_np.reshape([-1]))\n",
    "#     X = np.array(X)\n",
    "#     return X\n",
    "\n",
    "def get_img_label(path, mode,num_classes=35):\n",
    "    images_dir, labels, table = load_ccpd(dataset_path[path],mode=mode)\n",
    "    images = readCcpdImg(images_dir)\n",
    "    labels = np.array(labels)\n",
    "    labels = to_categorical(labels, num_classes=num_classes)\n",
    "    return images,labels\n",
    "\n",
    "def get_encoder(input_shape=(32,16,3)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=[3, 3], padding=\"same\", activation='relu',input_shape=input_shape))\n",
    "    model.add(MaxPool2D(pool_size=[2, 2], strides=2, padding='same'))\n",
    "    model.add(Conv2D(48, kernel_size=[3, 3], padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=[2, 2], strides=2, padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "def get_task(input_shape=(1536,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation='relu',input_shape=input_shape))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(34, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "def get_discriminator(input_shape=(1536,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation='relu',input_shape=input_shape))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "base_images,base_labels = get_img_label('base', 'all', num_classes=34)\n",
    "weather_images,weather_labels = get_img_label('weather', 'all', num_classes=34)\n",
    "weather_images_t,weather_labels_t = get_img_label('weather', 'train', num_classes=34)\n",
    "challenge_images,challenge_labels = get_img_label('challenge', 'all', num_classes=34)\n",
    "challenge_images_t,challenge_labels_t = get_img_label('challenge', 'train', num_classes=34)\n",
    "db_images,db_labels = get_img_label('db', 'all', num_classes=34)\n",
    "db_images_t,db_labels_t = get_img_label('db', 'train', num_classes=34)\n",
    "fn_images,fn_labels = get_img_label('fn', 'all', num_classes=34)\n",
    "fn_images_t,fn_labels_t = get_img_label('fn', 'train', num_classes=34)\n",
    "print(np.shape(base_images))\n",
    "#model = get_encoder()\n",
    "#model.build(input_shape=[None, 32, 16, 3])\n",
    "#model.summary()\n",
    "print(\"load data finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7371a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 32, 16, 3)\n",
      "(8446, 34)\n",
      "(762, 32, 16, 3)\n",
      "(762, 34)\n",
      "(3812, 32, 16, 3)\n",
      "(3812, 34)\n",
      "Epoch 1/86\n",
      "286/286 [==============================] - 3s 7ms/step - loss: 2.4887 - acc: 0.3724 - disc_loss: 1.1613 - disc_acc: 0.7014 - val_loss: 2.1610 - val_acc: 0.3927\n",
      "Epoch 2/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 1.5385 - acc: 0.6183 - disc_loss: 1.0674 - disc_acc: 0.7355 - val_loss: 1.3717 - val_acc: 0.6645\n",
      "Epoch 3/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 1.0035 - acc: 0.7410 - disc_loss: 1.0167 - disc_acc: 0.7487 - val_loss: 0.9908 - val_acc: 0.7411\n",
      "Epoch 4/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.7682 - acc: 0.7957 - disc_loss: 0.9793 - disc_acc: 0.7625 - val_loss: 0.8267 - val_acc: 0.7878\n",
      "Epoch 5/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.6273 - acc: 0.8362 - disc_loss: 0.9544 - disc_acc: 0.7678 - val_loss: 0.7075 - val_acc: 0.8111\n",
      "Epoch 6/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.5244 - acc: 0.8642 - disc_loss: 0.9446 - disc_acc: 0.7739 - val_loss: 0.5644 - val_acc: 0.8612\n",
      "Epoch 7/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.4485 - acc: 0.8864 - disc_loss: 0.9179 - disc_acc: 0.7775 - val_loss: 0.5785 - val_acc: 0.8570\n",
      "Epoch 8/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.4026 - acc: 0.9002 - disc_loss: 0.9149 - disc_acc: 0.7800 - val_loss: 0.5372 - val_acc: 0.8675\n",
      "Epoch 9/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.3772 - acc: 0.9069 - disc_loss: 0.8666 - disc_acc: 0.7957 - val_loss: 0.5054 - val_acc: 0.8767\n",
      "Epoch 10/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.3322 - acc: 0.9191 - disc_loss: 0.8415 - disc_acc: 0.8049 - val_loss: 0.5009 - val_acc: 0.8788\n",
      "Epoch 11/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.2979 - acc: 0.9288 - disc_loss: 0.8364 - disc_acc: 0.8058 - val_loss: 0.4516 - val_acc: 0.8948\n",
      "Epoch 12/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.2759 - acc: 0.9334 - disc_loss: 0.7919 - disc_acc: 0.8171 - val_loss: 0.4097 - val_acc: 0.9084\n",
      "Epoch 13/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.2573 - acc: 0.9407 - disc_loss: 0.7822 - disc_acc: 0.8175 - val_loss: 0.3572 - val_acc: 0.9087\n",
      "Epoch 14/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.2324 - acc: 0.9473 - disc_loss: 0.7445 - disc_acc: 0.8329 - val_loss: 0.3434 - val_acc: 0.9208\n",
      "Epoch 15/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.2196 - acc: 0.9503 - disc_loss: 0.7400 - disc_acc: 0.8292 - val_loss: 0.4178 - val_acc: 0.8945\n",
      "Epoch 16/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.2029 - acc: 0.9552 - disc_loss: 0.6963 - disc_acc: 0.8452 - val_loss: 0.3140 - val_acc: 0.9284\n",
      "Epoch 17/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.1895 - acc: 0.9570 - disc_loss: 0.6697 - disc_acc: 0.8547 - val_loss: 0.3404 - val_acc: 0.9147\n",
      "Epoch 18/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.1770 - acc: 0.9612 - disc_loss: 0.6576 - disc_acc: 0.8546 - val_loss: 0.3237 - val_acc: 0.9189\n",
      "Epoch 19/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.1557 - acc: 0.9683 - disc_loss: 0.6457 - disc_acc: 0.8593 - val_loss: 0.2819 - val_acc: 0.9347\n",
      "Epoch 20/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.1496 - acc: 0.9696 - disc_loss: 0.5873 - disc_acc: 0.8772 - val_loss: 0.3112 - val_acc: 0.9234\n",
      "Epoch 21/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.1364 - acc: 0.9724 - disc_loss: 0.5603 - disc_acc: 0.8815 - val_loss: 0.2784 - val_acc: 0.9389\n",
      "Epoch 22/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.1394 - acc: 0.9695 - disc_loss: 0.5593 - disc_acc: 0.8823 - val_loss: 0.3631 - val_acc: 0.9063\n",
      "Epoch 23/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.1376 - acc: 0.9686 - disc_loss: 0.5653 - disc_acc: 0.8811 - val_loss: 0.2645 - val_acc: 0.9402\n",
      "Epoch 24/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.1213 - acc: 0.9756 - disc_loss: 0.5064 - disc_acc: 0.8953 - val_loss: 0.2687 - val_acc: 0.9373\n",
      "Epoch 25/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.1231 - acc: 0.9734 - disc_loss: 0.4887 - disc_acc: 0.9007 - val_loss: 0.2824 - val_acc: 0.9357\n",
      "Epoch 26/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.1012 - acc: 0.9803 - disc_loss: 0.4908 - disc_acc: 0.9023 - val_loss: 0.2797 - val_acc: 0.9331\n",
      "Epoch 27/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.1021 - acc: 0.9806 - disc_loss: 0.4658 - disc_acc: 0.9036 - val_loss: 0.2586 - val_acc: 0.9431\n",
      "Epoch 28/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0955 - acc: 0.9815 - disc_loss: 0.5098 - disc_acc: 0.8928 - val_loss: 0.3595 - val_acc: 0.9168\n",
      "Epoch 29/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0994 - acc: 0.9805 - disc_loss: 0.4779 - disc_acc: 0.9038 - val_loss: 0.2556 - val_acc: 0.9433\n",
      "Epoch 30/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0892 - acc: 0.9835 - disc_loss: 0.4761 - disc_acc: 0.9020 - val_loss: 0.3595 - val_acc: 0.9108\n",
      "Epoch 31/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0940 - acc: 0.9810 - disc_loss: 0.4477 - disc_acc: 0.9104 - val_loss: 0.3126 - val_acc: 0.9357\n",
      "Epoch 32/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0934 - acc: 0.9803 - disc_loss: 0.4466 - disc_acc: 0.9118 - val_loss: 0.2485 - val_acc: 0.9436\n",
      "Epoch 33/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0840 - acc: 0.9843 - disc_loss: 0.4489 - disc_acc: 0.9090 - val_loss: 0.2528 - val_acc: 0.9444\n",
      "Epoch 34/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0774 - acc: 0.9852 - disc_loss: 0.4456 - disc_acc: 0.9101 - val_loss: 0.2781 - val_acc: 0.9384\n",
      "Epoch 35/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0814 - acc: 0.9847 - disc_loss: 0.4262 - disc_acc: 0.9151 - val_loss: 0.2616 - val_acc: 0.9384\n",
      "Epoch 36/86\n",
      "286/286 [==============================] - 2s 8ms/step - loss: 0.0707 - acc: 0.9863 - disc_loss: 0.3934 - disc_acc: 0.9232 - val_loss: 0.2331 - val_acc: 0.9460\n",
      "Epoch 37/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0748 - acc: 0.9856 - disc_loss: 0.4385 - disc_acc: 0.9110 - val_loss: 0.2867 - val_acc: 0.9352\n",
      "Epoch 38/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0792 - acc: 0.9824 - disc_loss: 0.4255 - disc_acc: 0.9145 - val_loss: 0.2353 - val_acc: 0.9449\n",
      "Epoch 39/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0770 - acc: 0.9822 - disc_loss: 0.4498 - disc_acc: 0.9084 - val_loss: 0.2600 - val_acc: 0.9386\n",
      "Epoch 40/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0692 - acc: 0.9865 - disc_loss: 0.4369 - disc_acc: 0.9109 - val_loss: 0.2595 - val_acc: 0.9452\n",
      "Epoch 41/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0725 - acc: 0.9852 - disc_loss: 0.3933 - disc_acc: 0.9232 - val_loss: 0.2434 - val_acc: 0.9523\n",
      "Epoch 42/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0658 - acc: 0.9861 - disc_loss: 0.4159 - disc_acc: 0.9178 - val_loss: 0.2818 - val_acc: 0.9452\n",
      "Epoch 43/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0714 - acc: 0.9845 - disc_loss: 0.4046 - disc_acc: 0.9200 - val_loss: 0.2272 - val_acc: 0.9525\n",
      "Epoch 44/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0655 - acc: 0.9873 - disc_loss: 0.4084 - disc_acc: 0.9208 - val_loss: 0.2666 - val_acc: 0.9431\n",
      "Epoch 45/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0668 - acc: 0.9851 - disc_loss: 0.4451 - disc_acc: 0.9087 - val_loss: 0.2879 - val_acc: 0.9407\n",
      "Epoch 46/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0639 - acc: 0.9880 - disc_loss: 0.3431 - disc_acc: 0.9353 - val_loss: 0.2786 - val_acc: 0.9405\n",
      "Epoch 47/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0525 - acc: 0.9897 - disc_loss: 0.3597 - disc_acc: 0.9285 - val_loss: 0.2080 - val_acc: 0.9580\n",
      "Epoch 48/86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0543 - acc: 0.9890 - disc_loss: 0.3638 - disc_acc: 0.9286 - val_loss: 0.2743 - val_acc: 0.9349\n",
      "Epoch 49/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0554 - acc: 0.9891 - disc_loss: 0.3670 - disc_acc: 0.9306 - val_loss: 0.2202 - val_acc: 0.9541\n",
      "Epoch 50/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0618 - acc: 0.9872 - disc_loss: 0.4093 - disc_acc: 0.9197 - val_loss: 0.2469 - val_acc: 0.9449\n",
      "Epoch 51/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0552 - acc: 0.9878 - disc_loss: 0.3956 - disc_acc: 0.9219 - val_loss: 0.2547 - val_acc: 0.9481\n",
      "Epoch 52/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0552 - acc: 0.9885 - disc_loss: 0.3853 - disc_acc: 0.9235 - val_loss: 0.2484 - val_acc: 0.9478\n",
      "Epoch 53/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0568 - acc: 0.9890 - disc_loss: 0.4078 - disc_acc: 0.9167 - val_loss: 0.2362 - val_acc: 0.9496\n",
      "Epoch 54/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0510 - acc: 0.9893 - disc_loss: 0.4197 - disc_acc: 0.9156 - val_loss: 0.2506 - val_acc: 0.9478\n",
      "Epoch 55/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0545 - acc: 0.9874 - disc_loss: 0.3960 - disc_acc: 0.9209 - val_loss: 0.2513 - val_acc: 0.9491\n",
      "Epoch 56/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0543 - acc: 0.9875 - disc_loss: 0.3928 - disc_acc: 0.9223 - val_loss: 0.2437 - val_acc: 0.9494\n",
      "Epoch 57/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0499 - acc: 0.9892 - disc_loss: 0.3514 - disc_acc: 0.9312 - val_loss: 0.2427 - val_acc: 0.9475\n",
      "Epoch 58/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0473 - acc: 0.9898 - disc_loss: 0.3431 - disc_acc: 0.9332 - val_loss: 0.2384 - val_acc: 0.9507\n",
      "Epoch 59/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0521 - acc: 0.9898 - disc_loss: 0.3807 - disc_acc: 0.9253 - val_loss: 0.2877 - val_acc: 0.9475\n",
      "Epoch 60/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0531 - acc: 0.9878 - disc_loss: 0.3325 - disc_acc: 0.9381 - val_loss: 0.2380 - val_acc: 0.9554\n",
      "Epoch 61/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0430 - acc: 0.9923 - disc_loss: 0.3334 - disc_acc: 0.9335 - val_loss: 0.2091 - val_acc: 0.9599\n",
      "Epoch 62/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0446 - acc: 0.9892 - disc_loss: 0.3666 - disc_acc: 0.9265 - val_loss: 0.2399 - val_acc: 0.9575\n",
      "Epoch 63/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0470 - acc: 0.9897 - disc_loss: 0.3446 - disc_acc: 0.9320 - val_loss: 0.2331 - val_acc: 0.9567\n",
      "Epoch 64/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0498 - acc: 0.9881 - disc_loss: 0.4155 - disc_acc: 0.9167 - val_loss: 0.2123 - val_acc: 0.9546\n",
      "Epoch 65/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0448 - acc: 0.9913 - disc_loss: 0.4079 - disc_acc: 0.9179 - val_loss: 0.2146 - val_acc: 0.9593\n",
      "Epoch 66/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0402 - acc: 0.9920 - disc_loss: 0.3826 - disc_acc: 0.9248 - val_loss: 0.2201 - val_acc: 0.9609\n",
      "Epoch 67/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0409 - acc: 0.9918 - disc_loss: 0.3441 - disc_acc: 0.9324 - val_loss: 0.2439 - val_acc: 0.9523\n",
      "Epoch 68/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0486 - acc: 0.9893 - disc_loss: 0.3858 - disc_acc: 0.9222 - val_loss: 0.1974 - val_acc: 0.9635\n",
      "Epoch 69/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0551 - acc: 0.9879 - disc_loss: 0.4058 - disc_acc: 0.9191 - val_loss: 0.1944 - val_acc: 0.9599\n",
      "Epoch 70/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0443 - acc: 0.9899 - disc_loss: 0.3890 - disc_acc: 0.9249 - val_loss: 0.2218 - val_acc: 0.9588\n",
      "Epoch 71/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0473 - acc: 0.9899 - disc_loss: 0.4293 - disc_acc: 0.9126 - val_loss: 0.3179 - val_acc: 0.9336\n",
      "Epoch 72/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0428 - acc: 0.9915 - disc_loss: 0.4318 - disc_acc: 0.9137 - val_loss: 0.2019 - val_acc: 0.9643\n",
      "Epoch 73/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0499 - acc: 0.9872 - disc_loss: 0.4194 - disc_acc: 0.9172 - val_loss: 0.2481 - val_acc: 0.9494\n",
      "Epoch 74/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0394 - acc: 0.9921 - disc_loss: 0.4006 - disc_acc: 0.9185 - val_loss: 0.2284 - val_acc: 0.9578\n",
      "Epoch 75/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0416 - acc: 0.9911 - disc_loss: 0.4147 - disc_acc: 0.9166 - val_loss: 0.1888 - val_acc: 0.9662\n",
      "Epoch 76/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0420 - acc: 0.9917 - disc_loss: 0.4381 - disc_acc: 0.9110 - val_loss: 0.2995 - val_acc: 0.9407\n",
      "Epoch 77/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0460 - acc: 0.9891 - disc_loss: 0.3615 - disc_acc: 0.9291 - val_loss: 0.2108 - val_acc: 0.9604\n",
      "Epoch 78/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0449 - acc: 0.9895 - disc_loss: 0.3817 - disc_acc: 0.9226 - val_loss: 0.2086 - val_acc: 0.9565\n",
      "Epoch 79/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0399 - acc: 0.9915 - disc_loss: 0.3682 - disc_acc: 0.9269 - val_loss: 0.2356 - val_acc: 0.9525\n",
      "Epoch 80/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0434 - acc: 0.9905 - disc_loss: 0.3901 - disc_acc: 0.9210 - val_loss: 0.2302 - val_acc: 0.9596\n",
      "Epoch 81/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0417 - acc: 0.9904 - disc_loss: 0.4041 - disc_acc: 0.9175 - val_loss: 0.2050 - val_acc: 0.9549\n",
      "Epoch 82/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0411 - acc: 0.9902 - disc_loss: 0.3717 - disc_acc: 0.9283 - val_loss: 0.2658 - val_acc: 0.9491\n",
      "Epoch 83/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0355 - acc: 0.9938 - disc_loss: 0.3298 - disc_acc: 0.9351 - val_loss: 0.2622 - val_acc: 0.9457\n",
      "Epoch 84/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0414 - acc: 0.9910 - disc_loss: 0.3971 - disc_acc: 0.9192 - val_loss: 0.3851 - val_acc: 0.8995\n",
      "Epoch 85/86\n",
      "286/286 [==============================] - 2s 7ms/step - loss: 0.0432 - acc: 0.9896 - disc_loss: 0.3959 - disc_acc: 0.9194 - val_loss: 0.2160 - val_acc: 0.9633\n",
      "Epoch 86/86\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0426 - acc: 0.9891 - disc_loss: 0.3872 - disc_acc: 0.9208 - val_loss: 0.2166 - val_acc: 0.9625\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0393 - acc: 0.9935\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.2166 - acc: 0.9625\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(base_labels))\n",
    "print(np.shape(weather_images_t))\n",
    "print(np.shape(weather_labels_t))\n",
    "print(np.shape(weather_images))\n",
    "print(np.shape(weather_labels))\n",
    "\n",
    "weather_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "weather_model.fit(base_images, base_labels,weather_images_t,weather_labels_t, epochs=86,verbose=1,\n",
    "                  batch_size = 32,validation_data=(weather_images, weather_labels))\n",
    "weather_model.score(base_images, base_labels)\n",
    "weather_model.score(weather_images, weather_labels)\n",
    "weather_model.save_weights(save_check_pt+ '/weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb4500f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 32, 16, 3)\n",
      "(8446, 34)\n",
      "(109, 32, 16, 3)\n",
      "(109, 34)\n",
      "(548, 32, 16, 3)\n",
      "(548, 34)\n",
      "Epoch 1/60\n",
      "266/266 [==============================] - 3s 7ms/step - loss: 2.5330 - acc: 0.3594 - disc_loss: 0.8592 - disc_acc: 0.7959 - val_loss: 2.5350 - val_acc: 0.2828\n",
      "Epoch 2/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 1.6302 - acc: 0.5981 - disc_loss: 0.6473 - disc_acc: 0.8600 - val_loss: 2.0770 - val_acc: 0.4434\n",
      "Epoch 3/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 1.1359 - acc: 0.7069 - disc_loss: 0.5486 - disc_acc: 0.8911 - val_loss: 1.7939 - val_acc: 0.5091\n",
      "Epoch 4/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.8824 - acc: 0.7669 - disc_loss: 0.4726 - disc_acc: 0.9078 - val_loss: 1.7020 - val_acc: 0.5401\n",
      "Epoch 5/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.7337 - acc: 0.8085 - disc_loss: 0.3943 - disc_acc: 0.9272 - val_loss: 1.4442 - val_acc: 0.6624\n",
      "Epoch 6/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.6143 - acc: 0.8463 - disc_loss: 0.3548 - disc_acc: 0.9369 - val_loss: 1.3241 - val_acc: 0.6752\n",
      "Epoch 7/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.5370 - acc: 0.8631 - disc_loss: 0.2934 - disc_acc: 0.9522 - val_loss: 1.2525 - val_acc: 0.6697\n",
      "Epoch 8/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.4776 - acc: 0.8801 - disc_loss: 0.2517 - disc_acc: 0.9604 - val_loss: 1.2281 - val_acc: 0.6661\n",
      "Epoch 9/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.4533 - acc: 0.8859 - disc_loss: 0.2566 - disc_acc: 0.9557 - val_loss: 1.0825 - val_acc: 0.7026\n",
      "Epoch 10/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.3932 - acc: 0.9060 - disc_loss: 0.1863 - disc_acc: 0.9726 - val_loss: 1.2117 - val_acc: 0.6551\n",
      "Epoch 11/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.3648 - acc: 0.9088 - disc_loss: 0.2285 - disc_acc: 0.9627 - val_loss: 1.1469 - val_acc: 0.7080\n",
      "Epoch 12/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.3459 - acc: 0.9165 - disc_loss: 0.1840 - disc_acc: 0.9710 - val_loss: 1.0975 - val_acc: 0.7007\n",
      "Epoch 13/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.3202 - acc: 0.9234 - disc_loss: 0.1862 - disc_acc: 0.9703 - val_loss: 1.0329 - val_acc: 0.7500\n",
      "Epoch 14/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.2836 - acc: 0.9337 - disc_loss: 0.1376 - disc_acc: 0.9789 - val_loss: 1.1398 - val_acc: 0.6971\n",
      "Epoch 15/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.2742 - acc: 0.9358 - disc_loss: 0.1329 - disc_acc: 0.9809 - val_loss: 1.0487 - val_acc: 0.7226\n",
      "Epoch 16/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.2527 - acc: 0.9392 - disc_loss: 0.1343 - disc_acc: 0.9807 - val_loss: 1.0448 - val_acc: 0.7026\n",
      "Epoch 17/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.2418 - acc: 0.9421 - disc_loss: 0.1365 - disc_acc: 0.9792 - val_loss: 0.9962 - val_acc: 0.7591\n",
      "Epoch 18/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.2226 - acc: 0.9498 - disc_loss: 0.1180 - disc_acc: 0.9820 - val_loss: 0.9170 - val_acc: 0.7664\n",
      "Epoch 19/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.2060 - acc: 0.9544 - disc_loss: 0.1003 - disc_acc: 0.9852 - val_loss: 0.8502 - val_acc: 0.7883\n",
      "Epoch 20/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1996 - acc: 0.9581 - disc_loss: 0.1221 - disc_acc: 0.9798 - val_loss: 1.0093 - val_acc: 0.7628\n",
      "Epoch 21/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1866 - acc: 0.9597 - disc_loss: 0.1614 - disc_acc: 0.9725 - val_loss: 0.9208 - val_acc: 0.7810\n",
      "Epoch 22/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1778 - acc: 0.9612 - disc_loss: 0.0665 - disc_acc: 0.9909 - val_loss: 1.1757 - val_acc: 0.6953\n",
      "Epoch 23/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1633 - acc: 0.9637 - disc_loss: 0.1000 - disc_acc: 0.9848 - val_loss: 0.9382 - val_acc: 0.7810\n",
      "Epoch 24/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1667 - acc: 0.9635 - disc_loss: 0.1171 - disc_acc: 0.9826 - val_loss: 0.9908 - val_acc: 0.7536\n",
      "Epoch 25/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1566 - acc: 0.9654 - disc_loss: 0.0801 - disc_acc: 0.9886 - val_loss: 1.1239 - val_acc: 0.7609\n",
      "Epoch 26/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1485 - acc: 0.9669 - disc_loss: 0.0712 - disc_acc: 0.9897 - val_loss: 0.9010 - val_acc: 0.7865\n",
      "Epoch 27/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1308 - acc: 0.9727 - disc_loss: 0.0749 - disc_acc: 0.9901 - val_loss: 0.8193 - val_acc: 0.7993\n",
      "Epoch 28/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1235 - acc: 0.9749 - disc_loss: 0.0611 - disc_acc: 0.9915 - val_loss: 0.9420 - val_acc: 0.7956\n",
      "Epoch 29/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1257 - acc: 0.9739 - disc_loss: 0.0502 - disc_acc: 0.9937 - val_loss: 0.9675 - val_acc: 0.7920\n",
      "Epoch 30/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1226 - acc: 0.9742 - disc_loss: 0.0752 - disc_acc: 0.9885 - val_loss: 0.8020 - val_acc: 0.7974\n",
      "Epoch 31/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1142 - acc: 0.9773 - disc_loss: 0.0735 - disc_acc: 0.9881 - val_loss: 0.8520 - val_acc: 0.8047\n",
      "Epoch 32/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1104 - acc: 0.9766 - disc_loss: 0.0949 - disc_acc: 0.9854 - val_loss: 0.9274 - val_acc: 0.7682\n",
      "Epoch 33/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1039 - acc: 0.9794 - disc_loss: 0.0376 - disc_acc: 0.9955 - val_loss: 0.8824 - val_acc: 0.8066\n",
      "Epoch 34/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0953 - acc: 0.9806 - disc_loss: 0.0605 - disc_acc: 0.9908 - val_loss: 0.9335 - val_acc: 0.8120\n",
      "Epoch 35/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0951 - acc: 0.9813 - disc_loss: 0.0666 - disc_acc: 0.9905 - val_loss: 0.9745 - val_acc: 0.7719\n",
      "Epoch 36/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0877 - acc: 0.9835 - disc_loss: 0.0501 - disc_acc: 0.9932 - val_loss: 1.1774 - val_acc: 0.7573\n",
      "Epoch 37/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0924 - acc: 0.9802 - disc_loss: 0.0790 - disc_acc: 0.9881 - val_loss: 0.8277 - val_acc: 0.8120\n",
      "Epoch 38/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0813 - acc: 0.9845 - disc_loss: 0.0842 - disc_acc: 0.9864 - val_loss: 0.9095 - val_acc: 0.8084\n",
      "Epoch 39/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0725 - acc: 0.9874 - disc_loss: 0.0535 - disc_acc: 0.9927 - val_loss: 0.8284 - val_acc: 0.8412\n",
      "Epoch 40/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0677 - acc: 0.9880 - disc_loss: 0.0464 - disc_acc: 0.9931 - val_loss: 1.0249 - val_acc: 0.7828\n",
      "Epoch 41/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0770 - acc: 0.9842 - disc_loss: 0.0620 - disc_acc: 0.9906 - val_loss: 1.0991 - val_acc: 0.7956\n",
      "Epoch 42/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0736 - acc: 0.9852 - disc_loss: 0.0664 - disc_acc: 0.9900 - val_loss: 1.1534 - val_acc: 0.7938\n",
      "Epoch 43/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0904 - acc: 0.9795 - disc_loss: 0.0410 - disc_acc: 0.9944 - val_loss: 1.1410 - val_acc: 0.7646\n",
      "Epoch 44/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0721 - acc: 0.9853 - disc_loss: 0.0589 - disc_acc: 0.9904 - val_loss: 1.1508 - val_acc: 0.7810\n",
      "Epoch 45/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0679 - acc: 0.9871 - disc_loss: 0.0554 - disc_acc: 0.9909 - val_loss: 1.2601 - val_acc: 0.7536\n",
      "Epoch 46/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0595 - acc: 0.9900 - disc_loss: 0.0303 - disc_acc: 0.9957 - val_loss: 1.2844 - val_acc: 0.7755\n",
      "Epoch 47/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0648 - acc: 0.9868 - disc_loss: 0.0413 - disc_acc: 0.9938 - val_loss: 1.1390 - val_acc: 0.7810\n",
      "Epoch 48/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0574 - acc: 0.9891 - disc_loss: 0.0767 - disc_acc: 0.9879 - val_loss: 1.0937 - val_acc: 0.7883\n",
      "Epoch 49/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0596 - acc: 0.9889 - disc_loss: 0.0213 - disc_acc: 0.9974 - val_loss: 1.0284 - val_acc: 0.8212\n",
      "Epoch 50/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0448 - acc: 0.9929 - disc_loss: 0.0411 - disc_acc: 0.9941 - val_loss: 1.1241 - val_acc: 0.8102\n",
      "Epoch 51/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0490 - acc: 0.9904 - disc_loss: 0.0525 - disc_acc: 0.9919 - val_loss: 1.2506 - val_acc: 0.7482\n",
      "Epoch 52/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0652 - acc: 0.9858 - disc_loss: 0.0538 - disc_acc: 0.9914 - val_loss: 1.0243 - val_acc: 0.8029\n",
      "Epoch 53/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0547 - acc: 0.9893 - disc_loss: 0.0356 - disc_acc: 0.9947 - val_loss: 1.1878 - val_acc: 0.7682\n",
      "Epoch 54/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0531 - acc: 0.9896 - disc_loss: 0.0360 - disc_acc: 0.9946 - val_loss: 1.3364 - val_acc: 0.7482\n",
      "Epoch 55/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0438 - acc: 0.9926 - disc_loss: 0.0615 - disc_acc: 0.9896 - val_loss: 1.0962 - val_acc: 0.7901\n",
      "Epoch 56/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0469 - acc: 0.9918 - disc_loss: 0.0441 - disc_acc: 0.9932 - val_loss: 1.2567 - val_acc: 0.7883\n",
      "Epoch 57/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0524 - acc: 0.9892 - disc_loss: 0.0353 - disc_acc: 0.9944 - val_loss: 1.3026 - val_acc: 0.7755\n",
      "Epoch 58/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0512 - acc: 0.9906 - disc_loss: 0.0449 - disc_acc: 0.9927 - val_loss: 1.2031 - val_acc: 0.7901\n",
      "Epoch 59/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0379 - acc: 0.9935 - disc_loss: 0.0258 - disc_acc: 0.9963 - val_loss: 1.3185 - val_acc: 0.7719\n",
      "Epoch 60/60\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0593 - acc: 0.9857 - disc_loss: 0.0737 - disc_acc: 0.9898 - val_loss: 0.9371 - val_acc: 0.8285\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0378 - acc: 0.9964\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.9371 - acc: 0.8285\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(base_labels))\n",
    "print(np.shape(challenge_images_t))\n",
    "print(np.shape(challenge_labels_t))\n",
    "print(np.shape(challenge_images))\n",
    "print(np.shape(challenge_labels))\n",
    "challenge_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "challenge_model.fit(base_images, base_labels,challenge_images_t,challenge_labels_t,\n",
    "                    epochs=60,verbose=1,batch_size = 32,validation_data=(challenge_images, challenge_labels))\n",
    "challenge_model.score(base_images, base_labels)\n",
    "challenge_model.score(challenge_images, challenge_labels)\n",
    "challenge_model.save_weights(save_check_pt+ '/challenge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14fa698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 32, 16, 3)\n",
      "(8446, 34)\n",
      "(373, 32, 16, 3)\n",
      "(373, 34)\n",
      "(1869, 32, 16, 3)\n",
      "(1869, 34)\n",
      "Epoch 1/75\n",
      "269/269 [==============================] - 3s 7ms/step - loss: 2.5443 - acc: 0.3537 - disc_loss: 0.8921 - disc_acc: 0.8052 - val_loss: 2.2829 - val_acc: 0.4452\n",
      "Epoch 2/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 1.6853 - acc: 0.5856 - disc_loss: 0.9085 - disc_acc: 0.7903 - val_loss: 1.7879 - val_acc: 0.5543\n",
      "Epoch 3/75\n",
      "269/269 [==============================] - 2s 7ms/step - loss: 1.1820 - acc: 0.6931 - disc_loss: 0.9568 - disc_acc: 0.7736 - val_loss: 1.5569 - val_acc: 0.5805\n",
      "Epoch 4/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.9379 - acc: 0.7497 - disc_loss: 0.9612 - disc_acc: 0.7730 - val_loss: 1.2984 - val_acc: 0.6790\n",
      "Epoch 5/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.7875 - acc: 0.7876 - disc_loss: 0.9423 - disc_acc: 0.7747 - val_loss: 1.2078 - val_acc: 0.6891\n",
      "Epoch 6/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.6807 - acc: 0.8190 - disc_loss: 0.9394 - disc_acc: 0.7705 - val_loss: 1.1905 - val_acc: 0.7164\n",
      "Epoch 7/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.5779 - acc: 0.8516 - disc_loss: 0.9053 - disc_acc: 0.7882 - val_loss: 1.0021 - val_acc: 0.7410\n",
      "Epoch 8/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.5418 - acc: 0.8548 - disc_loss: 0.8457 - disc_acc: 0.8094 - val_loss: 1.1303 - val_acc: 0.6945\n",
      "Epoch 9/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.5103 - acc: 0.8676 - disc_loss: 0.7789 - disc_acc: 0.8267 - val_loss: 0.8632 - val_acc: 0.7785\n",
      "Epoch 10/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.4433 - acc: 0.8879 - disc_loss: 0.7554 - disc_acc: 0.8338 - val_loss: 0.8894 - val_acc: 0.7881\n",
      "Epoch 11/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.4194 - acc: 0.8921 - disc_loss: 0.7453 - disc_acc: 0.8343 - val_loss: 0.8303 - val_acc: 0.8074\n",
      "Epoch 12/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.3963 - acc: 0.8966 - disc_loss: 0.6845 - disc_acc: 0.8525 - val_loss: 0.8468 - val_acc: 0.7978\n",
      "Epoch 13/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.3725 - acc: 0.9044 - disc_loss: 0.6205 - disc_acc: 0.8705 - val_loss: 0.9847 - val_acc: 0.7298\n",
      "Epoch 14/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.3533 - acc: 0.9105 - disc_loss: 0.5995 - disc_acc: 0.8741 - val_loss: 0.7762 - val_acc: 0.8224\n",
      "Epoch 15/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.3315 - acc: 0.9157 - disc_loss: 0.5368 - disc_acc: 0.8889 - val_loss: 1.0343 - val_acc: 0.7715\n",
      "Epoch 16/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.3238 - acc: 0.9160 - disc_loss: 0.5511 - disc_acc: 0.8876 - val_loss: 0.7599 - val_acc: 0.8058\n",
      "Epoch 17/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.2881 - acc: 0.9268 - disc_loss: 0.5211 - disc_acc: 0.8903 - val_loss: 0.7416 - val_acc: 0.8224\n",
      "Epoch 18/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.2749 - acc: 0.9333 - disc_loss: 0.5388 - disc_acc: 0.8876 - val_loss: 0.7798 - val_acc: 0.8031\n",
      "Epoch 19/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.2647 - acc: 0.9325 - disc_loss: 0.5391 - disc_acc: 0.8880 - val_loss: 0.6831 - val_acc: 0.8475\n",
      "Epoch 20/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.2549 - acc: 0.9388 - disc_loss: 0.5289 - disc_acc: 0.8905 - val_loss: 0.6760 - val_acc: 0.8320\n",
      "Epoch 21/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.2413 - acc: 0.9425 - disc_loss: 0.4777 - disc_acc: 0.9037 - val_loss: 0.7120 - val_acc: 0.8384\n",
      "Epoch 22/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.2253 - acc: 0.9456 - disc_loss: 0.4738 - disc_acc: 0.9049 - val_loss: 0.7273 - val_acc: 0.8416\n",
      "Epoch 23/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.2118 - acc: 0.9480 - disc_loss: 0.4627 - disc_acc: 0.9062 - val_loss: 0.7491 - val_acc: 0.8266\n",
      "Epoch 24/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.2168 - acc: 0.9502 - disc_loss: 0.4412 - disc_acc: 0.9111 - val_loss: 0.6506 - val_acc: 0.8571\n",
      "Epoch 25/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1989 - acc: 0.9538 - disc_loss: 0.4322 - disc_acc: 0.9112 - val_loss: 0.9533 - val_acc: 0.8031\n",
      "Epoch 26/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.2063 - acc: 0.9489 - disc_loss: 0.4471 - disc_acc: 0.9104 - val_loss: 0.7154 - val_acc: 0.8266\n",
      "Epoch 27/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1911 - acc: 0.9543 - disc_loss: 0.4475 - disc_acc: 0.9090 - val_loss: 0.6088 - val_acc: 0.8587\n",
      "Epoch 28/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1673 - acc: 0.9639 - disc_loss: 0.4042 - disc_acc: 0.9185 - val_loss: 0.7139 - val_acc: 0.8427\n",
      "Epoch 29/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1704 - acc: 0.9589 - disc_loss: 0.4237 - disc_acc: 0.9145 - val_loss: 0.7639 - val_acc: 0.8448\n",
      "Epoch 30/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1672 - acc: 0.9603 - disc_loss: 0.3919 - disc_acc: 0.9216 - val_loss: 0.6188 - val_acc: 0.8497\n",
      "Epoch 31/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1632 - acc: 0.9628 - disc_loss: 0.3890 - disc_acc: 0.9255 - val_loss: 0.6264 - val_acc: 0.8571\n",
      "Epoch 32/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1519 - acc: 0.9640 - disc_loss: 0.3647 - disc_acc: 0.9275 - val_loss: 0.6710 - val_acc: 0.8497\n",
      "Epoch 33/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1630 - acc: 0.9605 - disc_loss: 0.4128 - disc_acc: 0.9145 - val_loss: 0.7008 - val_acc: 0.8470\n",
      "Epoch 34/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1431 - acc: 0.9686 - disc_loss: 0.4325 - disc_acc: 0.9112 - val_loss: 0.6170 - val_acc: 0.8561\n",
      "Epoch 35/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1470 - acc: 0.9653 - disc_loss: 0.4108 - disc_acc: 0.9169 - val_loss: 0.5744 - val_acc: 0.8711\n",
      "Epoch 36/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1270 - acc: 0.9713 - disc_loss: 0.3654 - disc_acc: 0.9277 - val_loss: 0.6547 - val_acc: 0.8732\n",
      "Epoch 37/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1358 - acc: 0.9671 - disc_loss: 0.3302 - disc_acc: 0.9362 - val_loss: 0.6676 - val_acc: 0.8609\n",
      "Epoch 38/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1179 - acc: 0.9742 - disc_loss: 0.3278 - disc_acc: 0.9345 - val_loss: 0.6083 - val_acc: 0.8775\n",
      "Epoch 39/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1225 - acc: 0.9734 - disc_loss: 0.3479 - disc_acc: 0.9340 - val_loss: 0.7011 - val_acc: 0.8673\n",
      "Epoch 40/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1093 - acc: 0.9749 - disc_loss: 0.3249 - disc_acc: 0.9352 - val_loss: 0.7755 - val_acc: 0.8459\n",
      "Epoch 41/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1155 - acc: 0.9728 - disc_loss: 0.3286 - disc_acc: 0.9363 - val_loss: 0.6316 - val_acc: 0.8753\n",
      "Epoch 42/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1204 - acc: 0.9702 - disc_loss: 0.3657 - disc_acc: 0.9274 - val_loss: 0.6928 - val_acc: 0.8480\n",
      "Epoch 43/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1124 - acc: 0.9746 - disc_loss: 0.4079 - disc_acc: 0.9207 - val_loss: 0.6213 - val_acc: 0.8577\n",
      "Epoch 44/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1059 - acc: 0.9763 - disc_loss: 0.3102 - disc_acc: 0.9403 - val_loss: 0.5993 - val_acc: 0.8641\n",
      "Epoch 45/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1088 - acc: 0.9741 - disc_loss: 0.3324 - disc_acc: 0.9355 - val_loss: 0.7249 - val_acc: 0.8609\n",
      "Epoch 46/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1125 - acc: 0.9731 - disc_loss: 0.2548 - disc_acc: 0.9534 - val_loss: 0.5604 - val_acc: 0.8780\n",
      "Epoch 47/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0988 - acc: 0.9782 - disc_loss: 0.2621 - disc_acc: 0.9528 - val_loss: 0.6813 - val_acc: 0.8614\n",
      "Epoch 48/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0958 - acc: 0.9772 - disc_loss: 0.3753 - disc_acc: 0.9259 - val_loss: 0.6320 - val_acc: 0.8705\n",
      "Epoch 49/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0943 - acc: 0.9803 - disc_loss: 0.3232 - disc_acc: 0.9389 - val_loss: 0.6650 - val_acc: 0.8555\n",
      "Epoch 50/75\n",
      "269/269 [==============================] - 2s 7ms/step - loss: 0.0931 - acc: 0.9788 - disc_loss: 0.3047 - disc_acc: 0.9423 - val_loss: 0.7107 - val_acc: 0.8448\n",
      "Epoch 51/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.1115 - acc: 0.9712 - disc_loss: 0.3184 - disc_acc: 0.9374 - val_loss: 0.6901 - val_acc: 0.8700\n",
      "Epoch 52/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0870 - acc: 0.9800 - disc_loss: 0.3450 - disc_acc: 0.9305 - val_loss: 0.5668 - val_acc: 0.8801\n",
      "Epoch 53/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0868 - acc: 0.9808 - disc_loss: 0.3073 - disc_acc: 0.9422 - val_loss: 0.6119 - val_acc: 0.8684\n",
      "Epoch 54/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0803 - acc: 0.9808 - disc_loss: 0.2855 - disc_acc: 0.9472 - val_loss: 0.6925 - val_acc: 0.8732\n",
      "Epoch 55/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0915 - acc: 0.9777 - disc_loss: 0.3320 - disc_acc: 0.9352 - val_loss: 0.5721 - val_acc: 0.8711\n",
      "Epoch 56/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0799 - acc: 0.9813 - disc_loss: 0.2797 - disc_acc: 0.9475 - val_loss: 0.6464 - val_acc: 0.8759\n",
      "Epoch 57/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0847 - acc: 0.9801 - disc_loss: 0.2871 - disc_acc: 0.9457 - val_loss: 0.7740 - val_acc: 0.8475\n",
      "Epoch 58/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0813 - acc: 0.9818 - disc_loss: 0.2927 - disc_acc: 0.9440 - val_loss: 0.6006 - val_acc: 0.8812\n",
      "Epoch 59/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0668 - acc: 0.9871 - disc_loss: 0.3072 - disc_acc: 0.9394 - val_loss: 0.6396 - val_acc: 0.8785\n",
      "Epoch 60/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0863 - acc: 0.9793 - disc_loss: 0.3095 - disc_acc: 0.9420 - val_loss: 0.5969 - val_acc: 0.8785\n",
      "Epoch 61/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0747 - acc: 0.9829 - disc_loss: 0.3126 - disc_acc: 0.9388 - val_loss: 0.6386 - val_acc: 0.8801\n",
      "Epoch 62/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0728 - acc: 0.9853 - disc_loss: 0.2965 - disc_acc: 0.9429 - val_loss: 0.8207 - val_acc: 0.8309\n",
      "Epoch 63/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0894 - acc: 0.9793 - disc_loss: 0.3242 - disc_acc: 0.9370 - val_loss: 0.6267 - val_acc: 0.8823\n",
      "Epoch 64/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0781 - acc: 0.9826 - disc_loss: 0.3254 - disc_acc: 0.9359 - val_loss: 0.5785 - val_acc: 0.8785\n",
      "Epoch 65/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0636 - acc: 0.9879 - disc_loss: 0.3387 - disc_acc: 0.9337 - val_loss: 0.6610 - val_acc: 0.8748\n",
      "Epoch 66/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0726 - acc: 0.9845 - disc_loss: 0.2306 - disc_acc: 0.9592 - val_loss: 0.5717 - val_acc: 0.8721\n",
      "Epoch 67/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0566 - acc: 0.9890 - disc_loss: 0.2642 - disc_acc: 0.9494 - val_loss: 0.6728 - val_acc: 0.8828\n",
      "Epoch 68/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0613 - acc: 0.9871 - disc_loss: 0.2719 - disc_acc: 0.9483 - val_loss: 0.5770 - val_acc: 0.8823\n",
      "Epoch 69/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0681 - acc: 0.9840 - disc_loss: 0.3195 - disc_acc: 0.9402 - val_loss: 0.6532 - val_acc: 0.8871\n",
      "Epoch 70/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0674 - acc: 0.9853 - disc_loss: 0.3833 - disc_acc: 0.9249 - val_loss: 0.6552 - val_acc: 0.8662\n",
      "Epoch 71/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0760 - acc: 0.9826 - disc_loss: 0.3321 - disc_acc: 0.9342 - val_loss: 0.5838 - val_acc: 0.8839\n",
      "Epoch 72/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0526 - acc: 0.9892 - disc_loss: 0.3370 - disc_acc: 0.9332 - val_loss: 0.6277 - val_acc: 0.8909\n",
      "Epoch 73/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0544 - acc: 0.9873 - disc_loss: 0.2876 - disc_acc: 0.9457 - val_loss: 0.6634 - val_acc: 0.8812\n",
      "Epoch 74/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0774 - acc: 0.9807 - disc_loss: 0.3192 - disc_acc: 0.9396 - val_loss: 0.7565 - val_acc: 0.8390\n",
      "Epoch 75/75\n",
      "269/269 [==============================] - 2s 6ms/step - loss: 0.0666 - acc: 0.9840 - disc_loss: 0.2517 - disc_acc: 0.9547 - val_loss: 0.5830 - val_acc: 0.8866\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0564 - acc: 0.9857\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5830 - acc: 0.8866\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(base_labels))\n",
    "print(np.shape(db_images_t))\n",
    "print(np.shape(db_labels_t))\n",
    "print(np.shape(db_images))\n",
    "print(np.shape(db_labels))\n",
    "db_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "db_model.fit(base_images, base_labels,db_images_t,db_labels_t, epochs=75,\n",
    "             verbose=1,batch_size = 32,validation_data=(db_images, db_labels))\n",
    "db_model.score(base_images, base_labels)\n",
    "db_model.score(db_images, db_labels)\n",
    "db_model.save_weights(save_check_pt+ '/db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29be5160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 32, 16, 3)\n",
      "(8446, 34)\n",
      "(48, 32, 16, 3)\n",
      "(48, 34)\n",
      "(243, 32, 16, 3)\n",
      "(243, 34)\n",
      "Epoch 1/60\n",
      "264/264 [==============================] - 3s 7ms/step - loss: 2.5634 - acc: 0.3475 - disc_loss: 0.9835 - disc_acc: 0.7653 - val_loss: 2.2690 - val_acc: 0.4527\n",
      "Epoch 2/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 1.6982 - acc: 0.5868 - disc_loss: 0.7798 - disc_acc: 0.8255 - val_loss: 1.5979 - val_acc: 0.5679\n",
      "Epoch 3/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 1.1712 - acc: 0.6941 - disc_loss: 0.6733 - disc_acc: 0.8565 - val_loss: 1.2043 - val_acc: 0.6708\n",
      "Epoch 4/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.9244 - acc: 0.7564 - disc_loss: 0.5387 - disc_acc: 0.8946 - val_loss: 1.0022 - val_acc: 0.7037\n",
      "Epoch 5/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.7720 - acc: 0.7920 - disc_loss: 0.4310 - disc_acc: 0.9208 - val_loss: 0.7826 - val_acc: 0.8066\n",
      "Epoch 6/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.6478 - acc: 0.8303 - disc_loss: 0.3570 - disc_acc: 0.9387 - val_loss: 0.6121 - val_acc: 0.8724\n",
      "Epoch 7/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.5692 - acc: 0.8540 - disc_loss: 0.2614 - disc_acc: 0.9576 - val_loss: 0.5822 - val_acc: 0.8436\n",
      "Epoch 8/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.5130 - acc: 0.8688 - disc_loss: 0.2276 - disc_acc: 0.9636 - val_loss: 0.5228 - val_acc: 0.8642\n",
      "Epoch 9/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.4720 - acc: 0.8771 - disc_loss: 0.1791 - disc_acc: 0.9723 - val_loss: 0.4525 - val_acc: 0.8971\n",
      "Epoch 10/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.4100 - acc: 0.8988 - disc_loss: 0.1158 - disc_acc: 0.9843 - val_loss: 0.4576 - val_acc: 0.8683\n",
      "Epoch 11/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.3838 - acc: 0.9003 - disc_loss: 0.1920 - disc_acc: 0.9675 - val_loss: 0.4316 - val_acc: 0.8765\n",
      "Epoch 12/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.3618 - acc: 0.9071 - disc_loss: 0.1570 - disc_acc: 0.9744 - val_loss: 0.4122 - val_acc: 0.8765\n",
      "Epoch 13/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.3383 - acc: 0.9189 - disc_loss: 0.1012 - disc_acc: 0.9857 - val_loss: 0.3562 - val_acc: 0.9053\n",
      "Epoch 14/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.3025 - acc: 0.9254 - disc_loss: 0.1055 - disc_acc: 0.9830 - val_loss: 0.3315 - val_acc: 0.8930\n",
      "Epoch 15/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.2839 - acc: 0.9313 - disc_loss: 0.0927 - disc_acc: 0.9858 - val_loss: 0.3105 - val_acc: 0.9177\n",
      "Epoch 16/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.2697 - acc: 0.9337 - disc_loss: 0.0571 - disc_acc: 0.9922 - val_loss: 0.2850 - val_acc: 0.9095\n",
      "Epoch 17/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.2440 - acc: 0.9429 - disc_loss: 0.0676 - disc_acc: 0.9890 - val_loss: 0.2623 - val_acc: 0.9465\n",
      "Epoch 18/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.2226 - acc: 0.9482 - disc_loss: 0.0607 - disc_acc: 0.9906 - val_loss: 0.2233 - val_acc: 0.9424\n",
      "Epoch 19/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.2080 - acc: 0.9534 - disc_loss: 0.0480 - disc_acc: 0.9929 - val_loss: 0.2234 - val_acc: 0.9506\n",
      "Epoch 20/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.2006 - acc: 0.9550 - disc_loss: 0.0540 - disc_acc: 0.9923 - val_loss: 0.2352 - val_acc: 0.9547\n",
      "Epoch 21/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.1900 - acc: 0.9556 - disc_loss: 0.1438 - disc_acc: 0.9775 - val_loss: 0.1894 - val_acc: 0.9506\n",
      "Epoch 22/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.1824 - acc: 0.9583 - disc_loss: 0.1146 - disc_acc: 0.9819 - val_loss: 0.2592 - val_acc: 0.9300\n",
      "Epoch 23/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.1643 - acc: 0.9634 - disc_loss: 0.0814 - disc_acc: 0.9863 - val_loss: 0.2238 - val_acc: 0.9300\n",
      "Epoch 24/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.1640 - acc: 0.9629 - disc_loss: 0.0473 - disc_acc: 0.9945 - val_loss: 0.2368 - val_acc: 0.9506\n",
      "Epoch 25/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.1583 - acc: 0.9660 - disc_loss: 0.0305 - disc_acc: 0.9965 - val_loss: 0.1553 - val_acc: 0.9506\n",
      "Epoch 26/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.1415 - acc: 0.9690 - disc_loss: 0.0503 - disc_acc: 0.9925 - val_loss: 0.1393 - val_acc: 0.9630\n",
      "Epoch 27/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.1333 - acc: 0.9709 - disc_loss: 0.0359 - disc_acc: 0.9946 - val_loss: 0.1486 - val_acc: 0.9547\n",
      "Epoch 28/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.1236 - acc: 0.9750 - disc_loss: 0.1209 - disc_acc: 0.9797 - val_loss: 0.1449 - val_acc: 0.9506\n",
      "Epoch 29/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.1214 - acc: 0.9746 - disc_loss: 0.0232 - disc_acc: 0.9968 - val_loss: 0.1620 - val_acc: 0.9630\n",
      "Epoch 30/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.1101 - acc: 0.9776 - disc_loss: 0.0111 - disc_acc: 0.9991 - val_loss: 0.1573 - val_acc: 0.9547\n",
      "Epoch 31/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.1043 - acc: 0.9801 - disc_loss: 0.0244 - disc_acc: 0.9962 - val_loss: 0.1480 - val_acc: 0.9630\n",
      "Epoch 32/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.1026 - acc: 0.9793 - disc_loss: 0.0317 - disc_acc: 0.9954 - val_loss: 0.1412 - val_acc: 0.9547\n",
      "Epoch 33/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.1140 - acc: 0.9754 - disc_loss: 0.0654 - disc_acc: 0.9900 - val_loss: 0.1718 - val_acc: 0.9630\n",
      "Epoch 34/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0994 - acc: 0.9790 - disc_loss: 0.0157 - disc_acc: 0.9983 - val_loss: 0.1247 - val_acc: 0.9588\n",
      "Epoch 35/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0953 - acc: 0.9809 - disc_loss: 0.0182 - disc_acc: 0.9974 - val_loss: 0.1453 - val_acc: 0.9588\n",
      "Epoch 36/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0857 - acc: 0.9820 - disc_loss: 0.0407 - disc_acc: 0.9932 - val_loss: 0.1492 - val_acc: 0.9630\n",
      "Epoch 37/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0807 - acc: 0.9839 - disc_loss: 0.0483 - disc_acc: 0.9923 - val_loss: 0.1376 - val_acc: 0.9630\n",
      "Epoch 38/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0740 - acc: 0.9875 - disc_loss: 0.0196 - disc_acc: 0.9971 - val_loss: 0.1829 - val_acc: 0.9424\n",
      "Epoch 39/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0842 - acc: 0.9832 - disc_loss: 0.0263 - disc_acc: 0.9965 - val_loss: 0.1179 - val_acc: 0.9630\n",
      "Epoch 40/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0679 - acc: 0.9870 - disc_loss: 0.0194 - disc_acc: 0.9977 - val_loss: 0.1781 - val_acc: 0.9547\n",
      "Epoch 41/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0680 - acc: 0.9860 - disc_loss: 0.0088 - disc_acc: 0.9989 - val_loss: 0.1278 - val_acc: 0.9630\n",
      "Epoch 42/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0772 - acc: 0.9843 - disc_loss: 0.1574 - disc_acc: 0.9772 - val_loss: 0.1935 - val_acc: 0.9465\n",
      "Epoch 43/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0674 - acc: 0.9882 - disc_loss: 0.0395 - disc_acc: 0.9946 - val_loss: 0.1433 - val_acc: 0.9712\n",
      "Epoch 44/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0729 - acc: 0.9857 - disc_loss: 0.0227 - disc_acc: 0.9967 - val_loss: 0.1144 - val_acc: 0.9630\n",
      "Epoch 45/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0550 - acc: 0.9916 - disc_loss: 0.0134 - disc_acc: 0.9984 - val_loss: 0.4223 - val_acc: 0.8930\n",
      "Epoch 46/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0637 - acc: 0.9865 - disc_loss: 0.0409 - disc_acc: 0.9942 - val_loss: 0.1416 - val_acc: 0.9424\n",
      "Epoch 47/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0558 - acc: 0.9892 - disc_loss: 0.0280 - disc_acc: 0.9963 - val_loss: 0.1379 - val_acc: 0.9506\n",
      "Epoch 48/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0485 - acc: 0.9909 - disc_loss: 0.0516 - disc_acc: 0.9926 - val_loss: 0.2044 - val_acc: 0.9506\n",
      "Epoch 49/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0515 - acc: 0.9905 - disc_loss: 0.0144 - disc_acc: 0.9981 - val_loss: 0.1014 - val_acc: 0.9630\n",
      "Epoch 50/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0506 - acc: 0.9905 - disc_loss: 0.0150 - disc_acc: 0.9977 - val_loss: 0.1982 - val_acc: 0.9547\n",
      "Epoch 51/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0507 - acc: 0.9899 - disc_loss: 0.0151 - disc_acc: 0.9980 - val_loss: 0.1060 - val_acc: 0.9712\n",
      "Epoch 52/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0371 - acc: 0.9938 - disc_loss: 0.0042 - disc_acc: 0.9995 - val_loss: 0.0967 - val_acc: 0.9753\n",
      "Epoch 53/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0691 - acc: 0.9847 - disc_loss: 0.0780 - disc_acc: 0.9883 - val_loss: 0.1328 - val_acc: 0.9753\n",
      "Epoch 54/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0358 - acc: 0.9949 - disc_loss: 0.0126 - disc_acc: 0.9988 - val_loss: 0.0818 - val_acc: 0.9671\n",
      "Epoch 55/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0330 - acc: 0.9947 - disc_loss: 0.0100 - disc_acc: 0.9989 - val_loss: 0.1048 - val_acc: 0.9630\n",
      "Epoch 56/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0499 - acc: 0.9888 - disc_loss: 0.0338 - disc_acc: 0.9948 - val_loss: 0.2016 - val_acc: 0.9547\n",
      "Epoch 57/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0594 - acc: 0.9864 - disc_loss: 0.0480 - disc_acc: 0.9919 - val_loss: 0.1315 - val_acc: 0.9588\n",
      "Epoch 58/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0481 - acc: 0.9897 - disc_loss: 0.0153 - disc_acc: 0.9976 - val_loss: 0.1859 - val_acc: 0.9506\n",
      "Epoch 59/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0417 - acc: 0.9923 - disc_loss: 0.0036 - disc_acc: 0.9997 - val_loss: 0.1982 - val_acc: 0.9342\n",
      "Epoch 60/60\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.0416 - acc: 0.9916 - disc_loss: 0.0564 - disc_acc: 0.9920 - val_loss: 0.0968 - val_acc: 0.9753\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0320 - acc: 0.9970\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0968 - acc: 0.9753\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(base_labels))\n",
    "print(np.shape(fn_images_t))\n",
    "print(np.shape(fn_labels_t))\n",
    "print(np.shape(fn_images))\n",
    "print(np.shape(fn_labels))\n",
    "fn_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "fn_model.fit(base_images, base_labels,fn_images_t,fn_labels_t, epochs=60,verbose=1,\n",
    "             batch_size = 32,validation_data=(fn_images, fn_labels))\n",
    "fn_model.score(base_images, base_labels)\n",
    "fn_model.score(fn_images, fn_labels)\n",
    "fn_model.save_weights(save_check_pt+ '/fn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
