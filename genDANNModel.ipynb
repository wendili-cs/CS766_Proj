{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2410689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data finished!\n"
     ]
    }
   ],
   "source": [
    "import  os, glob\n",
    "import  random, csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import adapt\n",
    "from adapt.feature_based import DANN\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# The path of the datasets, use dict format\n",
    "dataset_path = {\"base\": \"dataset/ccpd/splitted_plates_base\", \n",
    "                \"challenge\":\"dataset/ccpd/splitted_plates_challenge\",\n",
    "               \"db\":\"dataset/ccpd/splitted_plates_db\",\n",
    "               \"fn\":\"dataset/ccpd/splitted_plates_fn\",\n",
    "               \"weather\":\"dataset/ccpd/splitted_plates_weather\"}\n",
    "save_check_pt = './checkpoints_DANN'\n",
    "\n",
    "def load_csv(root, filename, name2label):\n",
    "    # From csv file return images dir,labels list\n",
    "    if not os.path.exists(os.path.join(root, filename)):\n",
    "        images = []\n",
    "        for name in name2label.keys(): \n",
    "            images += glob.glob(os.path.join(root, name, '*.png'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpg'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpeg'))\n",
    "        #print(len(images), images)\n",
    "        random.shuffle(images) # shuffle images\n",
    "        with open(os.path.join(root, filename), mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for img in images:  \n",
    "                name = img.split(os.sep)[-2]\n",
    "                label = name2label[name]\n",
    "                writer.writerow([img, label])\n",
    "            print('written into csv file:', filename)\n",
    "    # read existed csv\n",
    "    images, labels = [], []\n",
    "    with open(os.path.join(root, filename)) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            img, label = row\n",
    "            label = int(label)\n",
    "            images.append(img)\n",
    "            labels.append(label) \n",
    "    # return img dir and label\n",
    "    return images, labels\n",
    "\n",
    "def load_ccpd(root, mode='train'):\n",
    "    name2label = {}  # \"sq...\":0\n",
    "    # iterate sub dir, sort, while keep mapping\n",
    "    for name in sorted(os.listdir(os.path.join(root))):\n",
    "        # skip non file folder\n",
    "        if not os.path.isdir(os.path.join(root, name)):\n",
    "            continue\n",
    "        # give each category a number\n",
    "        name2label[name] = len(name2label.keys())\n",
    "    images, labels = load_csv(root, 'images.csv', name2label)\n",
    "    if mode == 'train':  # 20%\n",
    "        images = images[:int(0.2 * len(images))]\n",
    "        labels = labels[:int(0.2 * len(labels))]\n",
    "    elif mode == 'val':  # 20% = 60%->80%\n",
    "        images = images[int(0.6 * len(images)):int(0.8 * len(images))]\n",
    "        labels = labels[int(0.6 * len(labels)):int(0.8 * len(labels))]\n",
    "    else:  # all\n",
    "        images = images\n",
    "        labels = labels\n",
    "    return images, labels, name2label\n",
    "\n",
    "# def readCcpdImg(images_dir):\n",
    "#     X = []\n",
    "#     for img_dir in images_dir:\n",
    "#         img = cv2.imread(img_dir)\n",
    "#         img = cv2.resize(img,(32,32))\n",
    "#         X.append(img)\n",
    "#     X = np.array(X)\n",
    "#     return X\n",
    "\n",
    "def readCcpdImg(images_dir):\n",
    "    X = []\n",
    "    for img_dir in images_dir:\n",
    "        img = Image.open(img_dir)\n",
    "        img = img.convert('L') # conver to grayscale images\n",
    "        img = img.resize([16, 32])\n",
    "        img_np = np.asarray(img)\n",
    "        X.append(img_np.reshape([-1]))\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "def get_img_label(path, mode,num_classes=35):\n",
    "    images_dir, labels, table = load_ccpd(dataset_path[path],mode=mode)\n",
    "    images = readCcpdImg(images_dir)\n",
    "    labels = np.array(labels)\n",
    "    labels = to_categorical(labels, num_classes=num_classes)\n",
    "    return images,labels\n",
    "\n",
    "def get_encoder(input_shape=(512,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu',\n",
    "                    input_shape=input_shape))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dense(128, activation=\"sigmoid\"))\n",
    "    return model\n",
    "\n",
    "def get_task(input_shape=(128,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu',input_shape=input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(34, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "def get_discriminator(input_shape=(128,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu',input_shape=input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "base_images,base_labels = get_img_label('base', 'all', num_classes=34)\n",
    "weather_images,weather_labels = get_img_label('weather', 'all', num_classes=34)\n",
    "weather_images_t,weather_labels_t = get_img_label('weather', 'train', num_classes=34)\n",
    "challenge_images,challenge_labels = get_img_label('challenge', 'all', num_classes=34)\n",
    "challenge_images_t,challenge_labels_t = get_img_label('challenge', 'train', num_classes=34)\n",
    "db_images,db_labels = get_img_label('db', 'all', num_classes=34)\n",
    "db_images_t,db_labels_t = get_img_label('db', 'train', num_classes=34)\n",
    "fn_images,fn_labels = get_img_label('fn', 'all', num_classes=34)\n",
    "fn_images_t,fn_labels_t = get_img_label('fn', 'train', num_classes=34)\n",
    "print(\"load data finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7371a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 512)\n",
      "(8446, 34)\n",
      "(762, 512)\n",
      "(762, 34)\n",
      "Epoch 1/80\n",
      "286/286 [==============================] - 2s 4ms/step - loss: 2.5840 - acc: 0.3446 - disc_loss: 1.3876 - disc_acc: 0.5387\n",
      "Epoch 2/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 1.7942 - acc: 0.5757 - disc_loss: 1.3503 - disc_acc: 0.5797\n",
      "Epoch 3/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 1.3818 - acc: 0.6590 - disc_loss: 1.3541 - disc_acc: 0.5729\n",
      "Epoch 4/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 1.1379 - acc: 0.6982 - disc_loss: 1.3481 - disc_acc: 0.5766\n",
      "Epoch 5/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.9356 - acc: 0.7500 - disc_loss: 1.3375 - disc_acc: 0.5905\n",
      "Epoch 6/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.8115 - acc: 0.7907 - disc_loss: 1.3204 - disc_acc: 0.6009\n",
      "Epoch 7/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.7039 - acc: 0.8198 - disc_loss: 1.3146 - disc_acc: 0.6064\n",
      "Epoch 8/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.5968 - acc: 0.8484 - disc_loss: 1.3176 - disc_acc: 0.6076\n",
      "Epoch 9/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.5328 - acc: 0.8673 - disc_loss: 1.3171 - disc_acc: 0.6048\n",
      "Epoch 10/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.4725 - acc: 0.8851 - disc_loss: 1.3155 - disc_acc: 0.6036\n",
      "Epoch 11/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.4242 - acc: 0.8944 - disc_loss: 1.3150 - disc_acc: 0.6072\n",
      "Epoch 12/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.3865 - acc: 0.9059 - disc_loss: 1.3120 - disc_acc: 0.6045\n",
      "Epoch 13/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.3512 - acc: 0.9127 - disc_loss: 1.3050 - disc_acc: 0.6145\n",
      "Epoch 14/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.3162 - acc: 0.9257 - disc_loss: 1.2996 - disc_acc: 0.6147\n",
      "Epoch 15/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2912 - acc: 0.9321 - disc_loss: 1.3029 - disc_acc: 0.6155\n",
      "Epoch 16/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2753 - acc: 0.9365 - disc_loss: 1.3109 - disc_acc: 0.6024\n",
      "Epoch 17/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2462 - acc: 0.9406 - disc_loss: 1.3011 - disc_acc: 0.6197\n",
      "Epoch 18/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2352 - acc: 0.9444 - disc_loss: 1.3140 - disc_acc: 0.6044\n",
      "Epoch 19/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2160 - acc: 0.9483 - disc_loss: 1.3039 - disc_acc: 0.6143\n",
      "Epoch 20/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2039 - acc: 0.9546 - disc_loss: 1.3040 - disc_acc: 0.6096\n",
      "Epoch 21/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1773 - acc: 0.9606 - disc_loss: 1.3097 - disc_acc: 0.6150\n",
      "Epoch 22/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1861 - acc: 0.9590 - disc_loss: 1.3036 - disc_acc: 0.6136\n",
      "Epoch 23/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1681 - acc: 0.9617 - disc_loss: 1.3049 - disc_acc: 0.6128\n",
      "Epoch 24/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1605 - acc: 0.9637 - disc_loss: 1.3044 - disc_acc: 0.6159\n",
      "Epoch 25/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1530 - acc: 0.9661 - disc_loss: 1.3052 - disc_acc: 0.6166\n",
      "Epoch 26/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1232 - acc: 0.9744 - disc_loss: 1.3067 - disc_acc: 0.6097\n",
      "Epoch 27/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1311 - acc: 0.9721 - disc_loss: 1.3097 - disc_acc: 0.6092\n",
      "Epoch 28/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1246 - acc: 0.9736 - disc_loss: 1.3138 - disc_acc: 0.6064\n",
      "Epoch 29/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1207 - acc: 0.9733 - disc_loss: 1.3093 - disc_acc: 0.6067\n",
      "Epoch 30/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1191 - acc: 0.9728 - disc_loss: 1.3176 - disc_acc: 0.6029\n",
      "Epoch 31/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1122 - acc: 0.9738 - disc_loss: 1.3231 - disc_acc: 0.6013\n",
      "Epoch 32/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0917 - acc: 0.9801 - disc_loss: 1.3183 - disc_acc: 0.5987\n",
      "Epoch 33/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1041 - acc: 0.9743 - disc_loss: 1.3131 - disc_acc: 0.5978\n",
      "Epoch 34/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1002 - acc: 0.9795 - disc_loss: 1.3116 - disc_acc: 0.6005\n",
      "Epoch 35/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0825 - acc: 0.9818 - disc_loss: 1.3155 - disc_acc: 0.6043\n",
      "Epoch 36/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0845 - acc: 0.9804 - disc_loss: 1.3170 - disc_acc: 0.6042\n",
      "Epoch 37/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0836 - acc: 0.9827 - disc_loss: 1.3145 - disc_acc: 0.6021\n",
      "Epoch 38/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0957 - acc: 0.9776 - disc_loss: 1.3210 - disc_acc: 0.6014\n",
      "Epoch 39/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0931 - acc: 0.9780 - disc_loss: 1.3223 - disc_acc: 0.5994\n",
      "Epoch 40/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0882 - acc: 0.9783 - disc_loss: 1.3162 - disc_acc: 0.6078\n",
      "Epoch 41/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0723 - acc: 0.9840 - disc_loss: 1.3285 - disc_acc: 0.5930\n",
      "Epoch 42/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0848 - acc: 0.9779 - disc_loss: 1.3279 - disc_acc: 0.5976\n",
      "Epoch 43/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0865 - acc: 0.9786 - disc_loss: 1.3263 - disc_acc: 0.5938\n",
      "Epoch 44/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0693 - acc: 0.9839 - disc_loss: 1.3200 - disc_acc: 0.5986\n",
      "Epoch 45/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0573 - acc: 0.9864 - disc_loss: 1.3190 - disc_acc: 0.5983\n",
      "Epoch 46/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0651 - acc: 0.9847 - disc_loss: 1.3288 - disc_acc: 0.5922\n",
      "Epoch 47/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0654 - acc: 0.9848 - disc_loss: 1.3259 - disc_acc: 0.5989\n",
      "Epoch 48/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0694 - acc: 0.9822 - disc_loss: 1.3297 - disc_acc: 0.5935\n",
      "Epoch 49/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0599 - acc: 0.9862 - disc_loss: 1.3244 - disc_acc: 0.6001\n",
      "Epoch 50/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0525 - acc: 0.9872 - disc_loss: 1.3184 - disc_acc: 0.5978\n",
      "Epoch 51/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0798 - acc: 0.9775 - disc_loss: 1.3294 - disc_acc: 0.5926\n",
      "Epoch 52/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0721 - acc: 0.9814 - disc_loss: 1.3209 - disc_acc: 0.5979\n",
      "Epoch 53/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0756 - acc: 0.9792 - disc_loss: 1.3176 - disc_acc: 0.5998\n",
      "Epoch 54/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0517 - acc: 0.9879 - disc_loss: 1.3128 - disc_acc: 0.6093\n",
      "Epoch 55/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0674 - acc: 0.9809 - disc_loss: 1.3260 - disc_acc: 0.5973\n",
      "Epoch 56/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0617 - acc: 0.9835 - disc_loss: 1.3167 - disc_acc: 0.5996\n",
      "Epoch 57/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0427 - acc: 0.9906 - disc_loss: 1.3236 - disc_acc: 0.5953\n",
      "Epoch 58/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0510 - acc: 0.9888 - disc_loss: 1.3220 - disc_acc: 0.5979\n",
      "Epoch 59/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0466 - acc: 0.9876 - disc_loss: 1.3206 - disc_acc: 0.5930\n",
      "Epoch 60/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0556 - acc: 0.9858 - disc_loss: 1.3236 - disc_acc: 0.5901\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0572 - acc: 0.9836 - disc_loss: 1.3194 - disc_acc: 0.5947\n",
      "Epoch 62/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0448 - acc: 0.9892 - disc_loss: 1.3250 - disc_acc: 0.5914\n",
      "Epoch 63/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0604 - acc: 0.9837 - disc_loss: 1.3201 - disc_acc: 0.5987\n",
      "Epoch 64/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0381 - acc: 0.9918 - disc_loss: 1.3187 - disc_acc: 0.5976\n",
      "Epoch 65/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0325 - acc: 0.9937 - disc_loss: 1.3329 - disc_acc: 0.5873\n",
      "Epoch 66/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0630 - acc: 0.9818 - disc_loss: 1.3259 - disc_acc: 0.5913\n",
      "Epoch 67/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0500 - acc: 0.9868 - disc_loss: 1.3258 - disc_acc: 0.5979\n",
      "Epoch 68/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0548 - acc: 0.9858 - disc_loss: 1.3270 - disc_acc: 0.5933\n",
      "Epoch 69/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0430 - acc: 0.9891 - disc_loss: 1.3139 - disc_acc: 0.6046\n",
      "Epoch 70/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0600 - acc: 0.9828 - disc_loss: 1.3228 - disc_acc: 0.5966\n",
      "Epoch 71/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0616 - acc: 0.9846 - disc_loss: 1.3242 - disc_acc: 0.5964\n",
      "Epoch 72/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0695 - acc: 0.9791 - disc_loss: 1.3216 - disc_acc: 0.5971\n",
      "Epoch 73/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0435 - acc: 0.9888 - disc_loss: 1.3126 - disc_acc: 0.6074\n",
      "Epoch 74/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0329 - acc: 0.9914 - disc_loss: 1.3136 - disc_acc: 0.6068\n",
      "Epoch 75/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0258 - acc: 0.9945 - disc_loss: 1.3215 - disc_acc: 0.5940\n",
      "Epoch 76/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0268 - acc: 0.9934 - disc_loss: 1.3237 - disc_acc: 0.5933\n",
      "Epoch 77/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0433 - acc: 0.9879 - disc_loss: 1.3275 - disc_acc: 0.5882\n",
      "Epoch 78/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0637 - acc: 0.9804 - disc_loss: 1.3307 - disc_acc: 0.5873\n",
      "Epoch 79/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0415 - acc: 0.9892 - disc_loss: 1.3213 - disc_acc: 0.5938\n",
      "Epoch 80/80\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0303 - acc: 0.9927 - disc_loss: 1.3206 - disc_acc: 0.5933\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0245 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.3952 - acc: 0.9307\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(base_labels))\n",
    "print(np.shape(weather_images_t))\n",
    "print(np.shape(weather_labels_t))\n",
    "weather_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "weather_model.fit(base_images, base_labels,weather_images_t,weather_labels_t, epochs=80,verbose=1,batch_size = 32)\n",
    "weather_model.score(base_images, base_labels)\n",
    "weather_model.score(weather_images, weather_labels)\n",
    "weather_model.save_weights(save_check_pt+ '/weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb4500f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 512)\n",
      "(8446, 34)\n",
      "(109, 512)\n",
      "(109, 34)\n",
      "Epoch 1/88\n",
      "266/266 [==============================] - 2s 4ms/step - loss: 2.5871 - acc: 0.3432 - disc_loss: 1.3922 - disc_acc: 0.5374\n",
      "Epoch 2/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 1.9034 - acc: 0.5450 - disc_loss: 1.3527 - disc_acc: 0.5742\n",
      "Epoch 3/88\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 1.4989 - acc: 0.6328 - disc_loss: 1.3287 - disc_acc: 0.5916\n",
      "Epoch 4/88\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 1.2621 - acc: 0.6747 - disc_loss: 1.3244 - disc_acc: 0.6020\n",
      "Epoch 5/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 1.0692 - acc: 0.7145 - disc_loss: 1.2905 - disc_acc: 0.6278\n",
      "Epoch 6/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.9586 - acc: 0.7421 - disc_loss: 1.2952 - disc_acc: 0.6184\n",
      "Epoch 7/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.8363 - acc: 0.7805 - disc_loss: 1.2829 - disc_acc: 0.6293\n",
      "Epoch 8/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.7454 - acc: 0.8062 - disc_loss: 1.2703 - disc_acc: 0.6417\n",
      "Epoch 9/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.6709 - acc: 0.8306 - disc_loss: 1.2652 - disc_acc: 0.6410\n",
      "Epoch 10/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.5941 - acc: 0.8531 - disc_loss: 1.2604 - disc_acc: 0.6384\n",
      "Epoch 11/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.5253 - acc: 0.8671 - disc_loss: 1.2294 - disc_acc: 0.6550\n",
      "Epoch 12/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.5060 - acc: 0.8714 - disc_loss: 1.2309 - disc_acc: 0.6652\n",
      "Epoch 13/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.4517 - acc: 0.8837 - disc_loss: 1.2113 - disc_acc: 0.6655\n",
      "Epoch 14/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.4232 - acc: 0.8933 - disc_loss: 1.2367 - disc_acc: 0.6502\n",
      "Epoch 15/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.3950 - acc: 0.9027 - disc_loss: 1.2386 - disc_acc: 0.6459\n",
      "Epoch 16/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.3588 - acc: 0.9133 - disc_loss: 1.2272 - disc_acc: 0.6538\n",
      "Epoch 17/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.3338 - acc: 0.9187 - disc_loss: 1.2180 - disc_acc: 0.6561\n",
      "Epoch 18/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.3070 - acc: 0.9213 - disc_loss: 1.2079 - disc_acc: 0.6706\n",
      "Epoch 19/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.2705 - acc: 0.9361 - disc_loss: 1.2327 - disc_acc: 0.6476\n",
      "Epoch 20/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.2765 - acc: 0.9348 - disc_loss: 1.2420 - disc_acc: 0.6436\n",
      "Epoch 21/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.2614 - acc: 0.9332 - disc_loss: 1.2332 - disc_acc: 0.6473\n",
      "Epoch 22/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.2329 - acc: 0.9438 - disc_loss: 1.2316 - disc_acc: 0.6456\n",
      "Epoch 23/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.2078 - acc: 0.9535 - disc_loss: 1.2049 - disc_acc: 0.6667\n",
      "Epoch 24/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.2016 - acc: 0.9530 - disc_loss: 1.2348 - disc_acc: 0.6427\n",
      "Epoch 25/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1962 - acc: 0.9546 - disc_loss: 1.2300 - disc_acc: 0.6472\n",
      "Epoch 26/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1787 - acc: 0.9608 - disc_loss: 1.2393 - disc_acc: 0.6436\n",
      "Epoch 27/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1699 - acc: 0.9605 - disc_loss: 1.2250 - disc_acc: 0.6625\n",
      "Epoch 28/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1718 - acc: 0.9604 - disc_loss: 1.2155 - disc_acc: 0.6604\n",
      "Epoch 29/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1762 - acc: 0.9591 - disc_loss: 1.2230 - disc_acc: 0.6512\n",
      "Epoch 30/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1511 - acc: 0.9642 - disc_loss: 1.2216 - disc_acc: 0.6550\n",
      "Epoch 31/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1576 - acc: 0.9633 - disc_loss: 1.2299 - disc_acc: 0.6526\n",
      "Epoch 32/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1500 - acc: 0.9661 - disc_loss: 1.2265 - disc_acc: 0.6514\n",
      "Epoch 33/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1353 - acc: 0.9688 - disc_loss: 1.2264 - disc_acc: 0.6555\n",
      "Epoch 34/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1252 - acc: 0.9715 - disc_loss: 1.2363 - disc_acc: 0.6468\n",
      "Epoch 35/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1210 - acc: 0.9731 - disc_loss: 1.2485 - disc_acc: 0.6324\n",
      "Epoch 36/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1232 - acc: 0.9731 - disc_loss: 1.2570 - disc_acc: 0.6319\n",
      "Epoch 37/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1322 - acc: 0.9693 - disc_loss: 1.2410 - disc_acc: 0.6508\n",
      "Epoch 38/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1228 - acc: 0.9718 - disc_loss: 1.2482 - disc_acc: 0.6397\n",
      "Epoch 39/88\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.1094 - acc: 0.9771 - disc_loss: 1.2546 - disc_acc: 0.6303\n",
      "Epoch 40/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1011 - acc: 0.9749 - disc_loss: 1.2528 - disc_acc: 0.6248\n",
      "Epoch 41/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0909 - acc: 0.9806 - disc_loss: 1.2777 - disc_acc: 0.6189\n",
      "Epoch 42/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0906 - acc: 0.9808 - disc_loss: 1.2466 - disc_acc: 0.6360\n",
      "Epoch 43/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1001 - acc: 0.9758 - disc_loss: 1.2556 - disc_acc: 0.6381\n",
      "Epoch 44/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1092 - acc: 0.9731 - disc_loss: 1.2402 - disc_acc: 0.6467\n",
      "Epoch 45/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0900 - acc: 0.9792 - disc_loss: 1.2251 - disc_acc: 0.6547\n",
      "Epoch 46/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.1054 - acc: 0.9725 - disc_loss: 1.2240 - disc_acc: 0.6473\n",
      "Epoch 47/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0989 - acc: 0.9773 - disc_loss: 1.2358 - disc_acc: 0.6365\n",
      "Epoch 48/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0902 - acc: 0.9785 - disc_loss: 1.2341 - disc_acc: 0.6522\n",
      "Epoch 49/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0762 - acc: 0.9827 - disc_loss: 1.2489 - disc_acc: 0.6325\n",
      "Epoch 50/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0738 - acc: 0.9851 - disc_loss: 1.2639 - disc_acc: 0.6232\n",
      "Epoch 51/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0870 - acc: 0.9784 - disc_loss: 1.2529 - disc_acc: 0.6260\n",
      "Epoch 52/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0672 - acc: 0.9851 - disc_loss: 1.2613 - disc_acc: 0.6205\n",
      "Epoch 53/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0845 - acc: 0.9788 - disc_loss: 1.2375 - disc_acc: 0.6500\n",
      "Epoch 54/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0842 - acc: 0.9792 - disc_loss: 1.2193 - disc_acc: 0.6618\n",
      "Epoch 55/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0639 - acc: 0.9857 - disc_loss: 1.2651 - disc_acc: 0.6171\n",
      "Epoch 56/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0675 - acc: 0.9834 - disc_loss: 1.2463 - disc_acc: 0.6333\n",
      "Epoch 57/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0731 - acc: 0.9824 - disc_loss: 1.2495 - disc_acc: 0.6310\n",
      "Epoch 58/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0783 - acc: 0.9811 - disc_loss: 1.2487 - disc_acc: 0.6350\n",
      "Epoch 59/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0684 - acc: 0.9837 - disc_loss: 1.2752 - disc_acc: 0.6200\n",
      "Epoch 60/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0769 - acc: 0.9801 - disc_loss: 1.2386 - disc_acc: 0.6362\n",
      "Epoch 61/88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0610 - acc: 0.9859 - disc_loss: 1.2670 - disc_acc: 0.6247\n",
      "Epoch 62/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0612 - acc: 0.9853 - disc_loss: 1.2718 - disc_acc: 0.6167\n",
      "Epoch 63/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0722 - acc: 0.9819 - disc_loss: 1.2609 - disc_acc: 0.6183\n",
      "Epoch 64/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0840 - acc: 0.9779 - disc_loss: 1.2631 - disc_acc: 0.6279\n",
      "Epoch 65/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0758 - acc: 0.9795 - disc_loss: 1.2273 - disc_acc: 0.6463\n",
      "Epoch 66/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0528 - acc: 0.9868 - disc_loss: 1.2486 - disc_acc: 0.6332\n",
      "Epoch 67/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0419 - acc: 0.9904 - disc_loss: 1.2470 - disc_acc: 0.6372\n",
      "Epoch 68/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0507 - acc: 0.9881 - disc_loss: 1.2548 - disc_acc: 0.6290\n",
      "Epoch 69/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0719 - acc: 0.9809 - disc_loss: 1.2401 - disc_acc: 0.6412\n",
      "Epoch 70/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0670 - acc: 0.9845 - disc_loss: 1.2463 - disc_acc: 0.6325\n",
      "Epoch 71/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0547 - acc: 0.9866 - disc_loss: 1.2414 - disc_acc: 0.6403\n",
      "Epoch 72/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0750 - acc: 0.9784 - disc_loss: 1.2175 - disc_acc: 0.6613\n",
      "Epoch 73/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0661 - acc: 0.9820 - disc_loss: 1.2208 - disc_acc: 0.6589\n",
      "Epoch 74/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0656 - acc: 0.9828 - disc_loss: 1.2634 - disc_acc: 0.6257\n",
      "Epoch 75/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0485 - acc: 0.9888 - disc_loss: 1.2401 - disc_acc: 0.6363\n",
      "Epoch 76/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0430 - acc: 0.9889 - disc_loss: 1.2704 - disc_acc: 0.6226\n",
      "Epoch 77/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0461 - acc: 0.9884 - disc_loss: 1.2617 - disc_acc: 0.6214\n",
      "Epoch 78/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0648 - acc: 0.9815 - disc_loss: 1.2508 - disc_acc: 0.6310\n",
      "Epoch 79/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0429 - acc: 0.9902 - disc_loss: 1.2492 - disc_acc: 0.6380\n",
      "Epoch 80/88\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.0454 - acc: 0.9894 - disc_loss: 1.2573 - disc_acc: 0.6261\n",
      "Epoch 81/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0565 - acc: 0.9862 - disc_loss: 1.2658 - disc_acc: 0.6286\n",
      "Epoch 82/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0685 - acc: 0.9806 - disc_loss: 1.2318 - disc_acc: 0.6383\n",
      "Epoch 83/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0459 - acc: 0.9893 - disc_loss: 1.2515 - disc_acc: 0.6284\n",
      "Epoch 84/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0408 - acc: 0.9908 - disc_loss: 1.2732 - disc_acc: 0.6275\n",
      "Epoch 85/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0621 - acc: 0.9826 - disc_loss: 1.2521 - disc_acc: 0.6351\n",
      "Epoch 86/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0648 - acc: 0.9840 - disc_loss: 1.2488 - disc_acc: 0.6402\n",
      "Epoch 87/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0506 - acc: 0.9867 - disc_loss: 1.2395 - disc_acc: 0.6446\n",
      "Epoch 88/88\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.0443 - acc: 0.9891 - disc_loss: 1.2711 - disc_acc: 0.6206\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0430 - acc: 0.9898\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9466 - acc: 0.8741\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(base_labels))\n",
    "print(np.shape(challenge_images_t))\n",
    "print(np.shape(challenge_labels_t))\n",
    "challenge_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "challenge_model.fit(base_images, base_labels,challenge_images_t,challenge_labels_t, epochs=88,verbose=1,batch_size = 32)\n",
    "challenge_model.score(base_images, base_labels)\n",
    "challenge_model.score(challenge_images, challenge_labels)\n",
    "challenge_model.save_weights(save_check_pt+ '/challenge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14fa698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 512)\n",
      "(8446, 34)\n",
      "(373, 512)\n",
      "(373, 34)\n",
      "Epoch 1/88\n",
      "269/269 [==============================] - 2s 4ms/step - loss: 2.6413 - acc: 0.3237 - disc_loss: 1.3721 - disc_acc: 0.5636\n",
      "Epoch 2/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 1.9469 - acc: 0.5269 - disc_loss: 1.3487 - disc_acc: 0.5862\n",
      "Epoch 3/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 1.5543 - acc: 0.6247 - disc_loss: 1.3456 - disc_acc: 0.5904\n",
      "Epoch 4/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 1.2766 - acc: 0.6739 - disc_loss: 1.3146 - disc_acc: 0.6201\n",
      "Epoch 5/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 1.1258 - acc: 0.7019 - disc_loss: 1.3198 - disc_acc: 0.6063\n",
      "Epoch 6/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.9506 - acc: 0.7401 - disc_loss: 1.3342 - disc_acc: 0.5906\n",
      "Epoch 7/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.8659 - acc: 0.7676 - disc_loss: 1.3082 - disc_acc: 0.6173\n",
      "Epoch 8/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.7556 - acc: 0.8031 - disc_loss: 1.3335 - disc_acc: 0.5891\n",
      "Epoch 9/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.6606 - acc: 0.8345 - disc_loss: 1.3047 - disc_acc: 0.6118\n",
      "Epoch 10/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.6033 - acc: 0.8473 - disc_loss: 1.3075 - disc_acc: 0.6176\n",
      "Epoch 11/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.5307 - acc: 0.8684 - disc_loss: 1.3084 - disc_acc: 0.6163\n",
      "Epoch 12/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.4956 - acc: 0.8761 - disc_loss: 1.3100 - disc_acc: 0.6086\n",
      "Epoch 13/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.4514 - acc: 0.8881 - disc_loss: 1.3131 - disc_acc: 0.6097\n",
      "Epoch 14/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.4163 - acc: 0.9000 - disc_loss: 1.3131 - disc_acc: 0.6122\n",
      "Epoch 15/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.3755 - acc: 0.9115 - disc_loss: 1.3081 - disc_acc: 0.6246\n",
      "Epoch 16/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.3529 - acc: 0.9136 - disc_loss: 1.2976 - disc_acc: 0.6286\n",
      "Epoch 17/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.3321 - acc: 0.9210 - disc_loss: 1.2871 - disc_acc: 0.6376\n",
      "Epoch 18/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.3154 - acc: 0.9219 - disc_loss: 1.3073 - disc_acc: 0.6128\n",
      "Epoch 19/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.2859 - acc: 0.9339 - disc_loss: 1.3057 - disc_acc: 0.6163\n",
      "Epoch 20/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.2708 - acc: 0.9352 - disc_loss: 1.3091 - disc_acc: 0.6097\n",
      "Epoch 21/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.2425 - acc: 0.9414 - disc_loss: 1.3031 - disc_acc: 0.6172\n",
      "Epoch 22/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.2283 - acc: 0.9461 - disc_loss: 1.2888 - disc_acc: 0.6297\n",
      "Epoch 23/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.2202 - acc: 0.9461 - disc_loss: 1.2885 - disc_acc: 0.6247\n",
      "Epoch 24/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.2099 - acc: 0.9506 - disc_loss: 1.2992 - disc_acc: 0.6254\n",
      "Epoch 25/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.2031 - acc: 0.9508 - disc_loss: 1.2905 - disc_acc: 0.6268\n",
      "Epoch 26/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1918 - acc: 0.9549 - disc_loss: 1.3034 - disc_acc: 0.6166\n",
      "Epoch 27/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1978 - acc: 0.9522 - disc_loss: 1.3132 - disc_acc: 0.6050\n",
      "Epoch 28/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1711 - acc: 0.9608 - disc_loss: 1.3142 - disc_acc: 0.6090\n",
      "Epoch 29/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1581 - acc: 0.9655 - disc_loss: 1.3186 - disc_acc: 0.6055\n",
      "Epoch 30/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1634 - acc: 0.9613 - disc_loss: 1.3083 - disc_acc: 0.6161\n",
      "Epoch 31/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1466 - acc: 0.9656 - disc_loss: 1.3181 - disc_acc: 0.6043\n",
      "Epoch 32/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1436 - acc: 0.9678 - disc_loss: 1.3235 - disc_acc: 0.6029\n",
      "Epoch 33/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1317 - acc: 0.9711 - disc_loss: 1.3036 - disc_acc: 0.6152\n",
      "Epoch 34/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1249 - acc: 0.9703 - disc_loss: 1.3201 - disc_acc: 0.5972\n",
      "Epoch 35/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1160 - acc: 0.9745 - disc_loss: 1.3165 - disc_acc: 0.5978\n",
      "Epoch 36/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1209 - acc: 0.9721 - disc_loss: 1.3234 - disc_acc: 0.5997\n",
      "Epoch 37/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1107 - acc: 0.9748 - disc_loss: 1.3201 - disc_acc: 0.5959\n",
      "Epoch 38/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1081 - acc: 0.9763 - disc_loss: 1.3137 - disc_acc: 0.6012\n",
      "Epoch 39/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0975 - acc: 0.9794 - disc_loss: 1.3168 - disc_acc: 0.6067\n",
      "Epoch 40/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0990 - acc: 0.9774 - disc_loss: 1.3192 - disc_acc: 0.6005\n",
      "Epoch 41/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1262 - acc: 0.9703 - disc_loss: 1.3301 - disc_acc: 0.5925\n",
      "Epoch 42/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0956 - acc: 0.9768 - disc_loss: 1.3130 - disc_acc: 0.6031\n",
      "Epoch 43/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.1292 - acc: 0.9691 - disc_loss: 1.3151 - disc_acc: 0.6058\n",
      "Epoch 44/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0904 - acc: 0.9803 - disc_loss: 1.3186 - disc_acc: 0.6055\n",
      "Epoch 45/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0910 - acc: 0.9773 - disc_loss: 1.3148 - disc_acc: 0.6034\n",
      "Epoch 46/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0810 - acc: 0.9820 - disc_loss: 1.3187 - disc_acc: 0.5993\n",
      "Epoch 47/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0711 - acc: 0.9862 - disc_loss: 1.3191 - disc_acc: 0.5991\n",
      "Epoch 48/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0622 - acc: 0.9862 - disc_loss: 1.3196 - disc_acc: 0.5979\n",
      "Epoch 49/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0784 - acc: 0.9824 - disc_loss: 1.3123 - disc_acc: 0.6029\n",
      "Epoch 50/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0676 - acc: 0.9848 - disc_loss: 1.3236 - disc_acc: 0.5921\n",
      "Epoch 51/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0774 - acc: 0.9822 - disc_loss: 1.3178 - disc_acc: 0.5972\n",
      "Epoch 52/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0857 - acc: 0.9786 - disc_loss: 1.3137 - disc_acc: 0.6004\n",
      "Epoch 53/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0813 - acc: 0.9808 - disc_loss: 1.3190 - disc_acc: 0.5987\n",
      "Epoch 54/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0634 - acc: 0.9857 - disc_loss: 1.3186 - disc_acc: 0.6073\n",
      "Epoch 55/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0952 - acc: 0.9740 - disc_loss: 1.3116 - disc_acc: 0.6099\n",
      "Epoch 56/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0726 - acc: 0.9822 - disc_loss: 1.3195 - disc_acc: 0.5990\n",
      "Epoch 57/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0541 - acc: 0.9883 - disc_loss: 1.3197 - disc_acc: 0.5940\n",
      "Epoch 58/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0598 - acc: 0.9850 - disc_loss: 1.3230 - disc_acc: 0.5934\n",
      "Epoch 59/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0584 - acc: 0.9862 - disc_loss: 1.3253 - disc_acc: 0.5871\n",
      "Epoch 60/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0686 - acc: 0.9810 - disc_loss: 1.3136 - disc_acc: 0.6042\n",
      "Epoch 61/88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0595 - acc: 0.9851 - disc_loss: 1.3100 - disc_acc: 0.6176\n",
      "Epoch 62/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0636 - acc: 0.9844 - disc_loss: 1.3167 - disc_acc: 0.6029\n",
      "Epoch 63/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0706 - acc: 0.9823 - disc_loss: 1.3185 - disc_acc: 0.6036\n",
      "Epoch 64/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0631 - acc: 0.9843 - disc_loss: 1.3242 - disc_acc: 0.5933\n",
      "Epoch 65/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0650 - acc: 0.9830 - disc_loss: 1.3089 - disc_acc: 0.6093\n",
      "Epoch 66/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0568 - acc: 0.9866 - disc_loss: 1.3126 - disc_acc: 0.6051\n",
      "Epoch 67/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0400 - acc: 0.9906 - disc_loss: 1.3194 - disc_acc: 0.5981\n",
      "Epoch 68/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0639 - acc: 0.9829 - disc_loss: 1.3175 - disc_acc: 0.5964\n",
      "Epoch 69/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0864 - acc: 0.9776 - disc_loss: 1.3108 - disc_acc: 0.6102\n",
      "Epoch 70/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0690 - acc: 0.9816 - disc_loss: 1.3274 - disc_acc: 0.5978\n",
      "Epoch 71/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0702 - acc: 0.9817 - disc_loss: 1.3123 - disc_acc: 0.6011\n",
      "Epoch 72/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0521 - acc: 0.9865 - disc_loss: 1.3076 - disc_acc: 0.6079\n",
      "Epoch 73/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0456 - acc: 0.9890 - disc_loss: 1.2994 - disc_acc: 0.6147\n",
      "Epoch 74/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0470 - acc: 0.9880 - disc_loss: 1.3250 - disc_acc: 0.5905\n",
      "Epoch 75/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0575 - acc: 0.9836 - disc_loss: 1.3112 - disc_acc: 0.6097\n",
      "Epoch 76/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0369 - acc: 0.9921 - disc_loss: 1.3144 - disc_acc: 0.6009\n",
      "Epoch 77/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0487 - acc: 0.9880 - disc_loss: 1.3112 - disc_acc: 0.6023\n",
      "Epoch 78/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0449 - acc: 0.9876 - disc_loss: 1.3228 - disc_acc: 0.5978\n",
      "Epoch 79/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0361 - acc: 0.9907 - disc_loss: 1.3302 - disc_acc: 0.5848\n",
      "Epoch 80/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0452 - acc: 0.9890 - disc_loss: 1.3318 - disc_acc: 0.5906\n",
      "Epoch 81/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0658 - acc: 0.9818 - disc_loss: 1.3019 - disc_acc: 0.6072\n",
      "Epoch 82/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0909 - acc: 0.9709 - disc_loss: 1.3077 - disc_acc: 0.6040\n",
      "Epoch 83/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0494 - acc: 0.9869 - disc_loss: 1.3064 - disc_acc: 0.6094\n",
      "Epoch 84/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0397 - acc: 0.9904 - disc_loss: 1.3173 - disc_acc: 0.6042\n",
      "Epoch 85/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0553 - acc: 0.9869 - disc_loss: 1.3030 - disc_acc: 0.6022\n",
      "Epoch 86/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0344 - acc: 0.9914 - disc_loss: 1.3172 - disc_acc: 0.6008\n",
      "Epoch 87/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0452 - acc: 0.9886 - disc_loss: 1.3249 - disc_acc: 0.5920\n",
      "Epoch 88/88\n",
      "269/269 [==============================] - 1s 4ms/step - loss: 0.0496 - acc: 0.9854 - disc_loss: 1.3156 - disc_acc: 0.6016\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x0000024E9C85CE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0503 - acc: 0.9864\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x0000024E9C85CE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.1822 - acc: 0.8325\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(base_labels))\n",
    "print(np.shape(db_images_t))\n",
    "print(np.shape(db_labels_t))\n",
    "db_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "db_model.fit(base_images, base_labels,db_images_t,db_labels_t, epochs=88,verbose=1,batch_size = 32)\n",
    "db_model.score(base_images, base_labels)\n",
    "db_model.score(db_images, db_labels)\n",
    "db_model.save_weights(save_check_pt+ '/db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29be5160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 512)\n",
      "(8446, 34)\n",
      "(48, 512)\n",
      "(48, 34)\n",
      "Epoch 1/70\n",
      "264/264 [==============================] - 2s 4ms/step - loss: 2.6245 - acc: 0.3191 - disc_loss: 1.3955 - disc_acc: 0.5229\n",
      "Epoch 2/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 1.8915 - acc: 0.5490 - disc_loss: 1.3484 - disc_acc: 0.5843\n",
      "Epoch 3/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 1.4343 - acc: 0.6463 - disc_loss: 1.3150 - disc_acc: 0.6156\n",
      "Epoch 4/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 1.1912 - acc: 0.6825 - disc_loss: 1.3160 - disc_acc: 0.6064\n",
      "Epoch 5/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 1.0100 - acc: 0.7308 - disc_loss: 1.2703 - disc_acc: 0.6454\n",
      "Epoch 6/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.8624 - acc: 0.7773 - disc_loss: 1.2486 - disc_acc: 0.6547\n",
      "Epoch 7/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.7437 - acc: 0.8142 - disc_loss: 1.2333 - disc_acc: 0.6616\n",
      "Epoch 8/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.6599 - acc: 0.8339 - disc_loss: 1.2259 - disc_acc: 0.6611\n",
      "Epoch 9/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.5724 - acc: 0.8572 - disc_loss: 1.2155 - disc_acc: 0.6679\n",
      "Epoch 10/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.5236 - acc: 0.8724 - disc_loss: 1.2132 - disc_acc: 0.6723\n",
      "Epoch 11/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.4932 - acc: 0.8742 - disc_loss: 1.1633 - disc_acc: 0.6991\n",
      "Epoch 12/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.4373 - acc: 0.8917 - disc_loss: 1.1921 - disc_acc: 0.6800\n",
      "Epoch 13/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.4071 - acc: 0.9004 - disc_loss: 1.1685 - disc_acc: 0.6917\n",
      "Epoch 14/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.3814 - acc: 0.9061 - disc_loss: 1.1687 - disc_acc: 0.6921\n",
      "Epoch 15/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.3419 - acc: 0.9155 - disc_loss: 1.1607 - disc_acc: 0.6949\n",
      "Epoch 16/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.3189 - acc: 0.9214 - disc_loss: 1.1744 - disc_acc: 0.6863\n",
      "Epoch 17/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.3025 - acc: 0.9292 - disc_loss: 1.1731 - disc_acc: 0.6768\n",
      "Epoch 18/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.2736 - acc: 0.9339 - disc_loss: 1.1940 - disc_acc: 0.6657\n",
      "Epoch 19/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.2592 - acc: 0.9384 - disc_loss: 1.1955 - disc_acc: 0.6760\n",
      "Epoch 20/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.2483 - acc: 0.9405 - disc_loss: 1.1924 - disc_acc: 0.6634\n",
      "Epoch 21/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.2226 - acc: 0.9486 - disc_loss: 1.1903 - disc_acc: 0.6801\n",
      "Epoch 22/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.2230 - acc: 0.9491 - disc_loss: 1.1844 - disc_acc: 0.6884\n",
      "Epoch 23/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.2102 - acc: 0.9503 - disc_loss: 1.1666 - disc_acc: 0.6983\n",
      "Epoch 24/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.1996 - acc: 0.9560 - disc_loss: 1.1750 - disc_acc: 0.6914\n",
      "Epoch 25/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.1830 - acc: 0.9588 - disc_loss: 1.1596 - disc_acc: 0.6978\n",
      "Epoch 26/70\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1850 - acc: 0.9563 - disc_loss: 1.1405 - disc_acc: 0.7155\n",
      "Epoch 27/70\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1739 - acc: 0.9602 - disc_loss: 1.1427 - disc_acc: 0.6985\n",
      "Epoch 28/70\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1561 - acc: 0.9653 - disc_loss: 1.1648 - disc_acc: 0.6860\n",
      "Epoch 29/70\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1584 - acc: 0.9635 - disc_loss: 1.1501 - disc_acc: 0.6877\n",
      "Epoch 30/70\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1412 - acc: 0.9692 - disc_loss: 1.1452 - disc_acc: 0.6946\n",
      "Epoch 31/70\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1384 - acc: 0.9692 - disc_loss: 1.1846 - disc_acc: 0.6769\n",
      "Epoch 32/70\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1301 - acc: 0.9693 - disc_loss: 1.2021 - disc_acc: 0.6660\n",
      "Epoch 33/70\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1311 - acc: 0.9706 - disc_loss: 1.1825 - disc_acc: 0.6738\n",
      "Epoch 34/70\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1337 - acc: 0.9672 - disc_loss: 1.1824 - disc_acc: 0.6846\n",
      "Epoch 35/70\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1123 - acc: 0.9736 - disc_loss: 1.1854 - disc_acc: 0.6769\n",
      "Epoch 36/70\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1181 - acc: 0.9755 - disc_loss: 1.1820 - disc_acc: 0.6824\n",
      "Epoch 37/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.1104 - acc: 0.9763 - disc_loss: 1.2061 - disc_acc: 0.6705\n",
      "Epoch 38/70\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.1182 - acc: 0.9735 - disc_loss: 1.1995 - disc_acc: 0.6675\n",
      "Epoch 39/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.1058 - acc: 0.9775 - disc_loss: 1.2021 - disc_acc: 0.6623\n",
      "Epoch 40/70\n",
      "264/264 [==============================] - 1s 5ms/step - loss: 0.1017 - acc: 0.9762 - disc_loss: 1.2130 - disc_acc: 0.6638\n",
      "Epoch 41/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.1202 - acc: 0.9718 - disc_loss: 1.1889 - disc_acc: 0.6678\n",
      "Epoch 42/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.1007 - acc: 0.9777 - disc_loss: 1.1964 - disc_acc: 0.6616\n",
      "Epoch 43/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0955 - acc: 0.9799 - disc_loss: 1.1963 - disc_acc: 0.6713\n",
      "Epoch 44/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0945 - acc: 0.9782 - disc_loss: 1.2125 - disc_acc: 0.6486\n",
      "Epoch 45/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0971 - acc: 0.9779 - disc_loss: 1.2276 - disc_acc: 0.6483\n",
      "Epoch 46/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.1090 - acc: 0.9725 - disc_loss: 1.2090 - disc_acc: 0.6613\n",
      "Epoch 47/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0963 - acc: 0.9775 - disc_loss: 1.1993 - disc_acc: 0.6652\n",
      "Epoch 48/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0791 - acc: 0.9822 - disc_loss: 1.1709 - disc_acc: 0.6723\n",
      "Epoch 49/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0718 - acc: 0.9840 - disc_loss: 1.2042 - disc_acc: 0.6643\n",
      "Epoch 50/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0783 - acc: 0.9824 - disc_loss: 1.2079 - disc_acc: 0.6550\n",
      "Epoch 51/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0911 - acc: 0.9775 - disc_loss: 1.2107 - disc_acc: 0.6581\n",
      "Epoch 52/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0882 - acc: 0.9787 - disc_loss: 1.1730 - disc_acc: 0.6727\n",
      "Epoch 53/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0766 - acc: 0.9812 - disc_loss: 1.2110 - disc_acc: 0.6563\n",
      "Epoch 54/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.1124 - acc: 0.9702 - disc_loss: 1.1725 - disc_acc: 0.6756\n",
      "Epoch 55/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0870 - acc: 0.9780 - disc_loss: 1.1781 - disc_acc: 0.6777\n",
      "Epoch 56/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0751 - acc: 0.9844 - disc_loss: 1.1803 - disc_acc: 0.6665\n",
      "Epoch 57/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0802 - acc: 0.9802 - disc_loss: 1.2162 - disc_acc: 0.6581\n",
      "Epoch 58/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0719 - acc: 0.9832 - disc_loss: 1.2308 - disc_acc: 0.6406\n",
      "Epoch 59/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0780 - acc: 0.9828 - disc_loss: 1.2318 - disc_acc: 0.6382\n",
      "Epoch 60/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0711 - acc: 0.9828 - disc_loss: 1.1605 - disc_acc: 0.6807\n",
      "Epoch 61/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0709 - acc: 0.9828 - disc_loss: 1.2002 - disc_acc: 0.6590\n",
      "Epoch 62/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0625 - acc: 0.9856 - disc_loss: 1.2163 - disc_acc: 0.6531\n",
      "Epoch 63/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0628 - acc: 0.9846 - disc_loss: 1.2118 - disc_acc: 0.6535\n",
      "Epoch 64/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0722 - acc: 0.9805 - disc_loss: 1.2020 - disc_acc: 0.6643\n",
      "Epoch 65/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0832 - acc: 0.9773 - disc_loss: 1.2103 - disc_acc: 0.6652\n",
      "Epoch 66/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0726 - acc: 0.9826 - disc_loss: 1.1898 - disc_acc: 0.6607\n",
      "Epoch 67/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0618 - acc: 0.9865 - disc_loss: 1.1856 - disc_acc: 0.6711\n",
      "Epoch 68/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0650 - acc: 0.9847 - disc_loss: 1.1957 - disc_acc: 0.6634\n",
      "Epoch 69/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0739 - acc: 0.9802 - disc_loss: 1.1930 - disc_acc: 0.6653\n",
      "Epoch 70/70\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0546 - acc: 0.9867 - disc_loss: 1.1895 - disc_acc: 0.6656\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0443 - acc: 0.9914\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2834 - acc: 0.9383\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(base_labels))\n",
    "print(np.shape(fn_images_t))\n",
    "print(np.shape(fn_labels_t))\n",
    "fn_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "fn_model.fit(base_images, base_labels,fn_images_t,fn_labels_t, epochs=70,verbose=1,batch_size = 32)\n",
    "fn_model.score(base_images, base_labels)\n",
    "fn_model.score(fn_images, fn_labels)\n",
    "fn_model.save_weights(save_check_pt+ '/fn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
