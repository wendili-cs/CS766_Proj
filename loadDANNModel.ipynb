{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa56db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os, glob\n",
    "import  random, csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import adapt\n",
    "from adapt.feature_based import DANN\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical  \n",
    "\n",
    "\n",
    "# The path of the datasets, use dict format\n",
    "dataset_path = {\"base\": \"dataset/ccpd/splitted_plates_base\", \n",
    "                \"challenge\":\"dataset/ccpd/splitted_plates_challenge\",\n",
    "               \"db\":\"dataset/ccpd/splitted_plates_db\",\n",
    "               \"fn\":\"dataset/ccpd/splitted_plates_fn\",\n",
    "               \"weather\":\"dataset/ccpd/splitted_plates_weather\"}\n",
    "save_check_pt = './checkpoints_DANN'\n",
    "my_epoch = 500\n",
    "\n",
    "def load_csv(root, filename, name2label):\n",
    "    # From csv file return images dir,labels list\n",
    "    if not os.path.exists(os.path.join(root, filename)):\n",
    "        images = []\n",
    "        for name in name2label.keys(): \n",
    "            images += glob.glob(os.path.join(root, name, '*.png'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpg'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpeg'))\n",
    "        #print(len(images), images)\n",
    "        random.shuffle(images) # shuffle images\n",
    "        with open(os.path.join(root, filename), mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for img in images:  \n",
    "                name = img.split(os.sep)[-2]\n",
    "                label = name2label[name]\n",
    "                writer.writerow([img, label])\n",
    "            print('written into csv file:', filename)\n",
    "    # read existed csv\n",
    "    images, labels = [], []\n",
    "    with open(os.path.join(root, filename)) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            img, label = row\n",
    "            label = int(label)\n",
    "            images.append(img)\n",
    "            labels.append(label) \n",
    "    # return img dir and label\n",
    "    return images, labels\n",
    "\n",
    "def load_ccpd(root, mode='train'):\n",
    "    name2label = {}  # \"sq...\":0\n",
    "    # iterate sub dir, sort, while keep mapping\n",
    "    for name in sorted(os.listdir(os.path.join(root))):\n",
    "        # skip non file folder\n",
    "        if not os.path.isdir(os.path.join(root, name)):\n",
    "            continue\n",
    "        # give each category a number\n",
    "        name2label[name] = len(name2label.keys())\n",
    "    images, labels = load_csv(root, 'images.csv', name2label)\n",
    "    if mode == 'train':  # 20%\n",
    "        images = images[:int(0.2 * len(images))]\n",
    "        labels = labels[:int(0.2 * len(labels))]\n",
    "    elif mode == 'val':  # 20% = 60%->80%\n",
    "        images = images[int(0.6 * len(images)):int(0.8 * len(images))]\n",
    "        labels = labels[int(0.6 * len(labels)):int(0.8 * len(labels))]\n",
    "    else:  # all\n",
    "        images = images\n",
    "        labels = labels\n",
    "    return images, labels, name2label\n",
    "\n",
    "# def readCcpdImg(images_dir):\n",
    "#     X = []\n",
    "#     for img_dir in images_dir:\n",
    "#         img = cv2.imread(img_dir)\n",
    "#         img = cv2.resize(img,(32,32))\n",
    "#         X.append(img)\n",
    "#     X = np.array(X)\n",
    "#     return X\n",
    "\n",
    "def readCcpdImg(images_dir):\n",
    "    X = []\n",
    "    for img_dir in images_dir:\n",
    "        img = Image.open(img_dir)\n",
    "        img = img.convert('L') # conver to grayscale images\n",
    "        img = img.resize([32, 16])\n",
    "        img_np = np.asarray(img)\n",
    "        X.append(img_np.reshape([-1]))\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "def get_img_label(path, mode,num_classes=35):\n",
    "    images_dir, labels, table = load_ccpd(dataset_path[path],mode=mode)\n",
    "    images = readCcpdImg(images_dir)\n",
    "    labels = np.array(labels)\n",
    "    labels = to_categorical(labels, num_classes=num_classes)\n",
    "    return images,labels\n",
    "\n",
    "def get_encoder(input_shape=(512,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu',\n",
    "                    input_shape=input_shape))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dense(128, activation=\"sigmoid\"))\n",
    "    return model\n",
    "\n",
    "def get_task(input_shape=(128,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu',input_shape=input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(35, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "def get_discriminator(input_shape=(128,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu',input_shape=input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "base_images,base_labels = get_img_label('base', 'all', num_classes=35)\n",
    "weather_images,weather_labels = get_img_label('weather', 'all', num_classes=35)\n",
    "weather_images_t,weather_labels_t = get_img_label('weather', 'train', num_classes=35)\n",
    "challenge_images,challenge_labels = get_img_label('challenge', 'all', num_classes=35)\n",
    "challenge_images_t,challenge_labels_t = get_img_label('challenge', 'train', num_classes=35)\n",
    "db_images,db_labels = get_img_label('db', 'all', num_classes=35)\n",
    "db_images_t,db_labels_t = get_img_label('db', 'train', num_classes=35)\n",
    "fn_images,fn_labels = get_img_label('fn', 'all', num_classes=35)\n",
    "fn_images_t,fn_labels_t = get_img_label('fn', 'train', num_classes=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6335631b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 123ms/step - loss: 4.0621 - acc: 0.7644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       248\n",
      "           1       0.84      0.93      0.88       137\n",
      "           2       0.92      0.96      0.94       231\n",
      "           3       0.98      0.94      0.96       172\n",
      "           4       0.88      0.91      0.89        78\n",
      "           5       0.99      0.89      0.93       233\n",
      "           6       0.96      0.94      0.95       236\n",
      "           7       0.90      0.96      0.93       213\n",
      "           8       0.96      0.96      0.96       257\n",
      "           9       0.92      0.96      0.94       224\n",
      "          10       0.97      0.98      0.97       748\n",
      "          11       1.00      0.88      0.94        50\n",
      "          12       0.89      0.98      0.93        49\n",
      "          13       0.74      0.90      0.81        48\n",
      "          14       0.85      0.79      0.81        28\n",
      "          15       0.90      0.90      0.90        40\n",
      "          16       0.94      0.80      0.87        41\n",
      "          17       0.86      0.89      0.88        57\n",
      "          18       0.00      0.00      0.00        45\n",
      "          19       0.00      0.00      0.00        53\n",
      "          20       0.00      0.00      0.00        41\n",
      "          21       0.00      0.00      0.00        49\n",
      "          22       0.00      0.00      0.00        54\n",
      "          23       0.00      0.00      0.00        31\n",
      "          24       0.00      0.00      0.00        36\n",
      "          25       0.00      0.00      0.00        44\n",
      "          26       0.00      0.00      0.00        58\n",
      "          27       0.00      0.00      0.00        35\n",
      "          28       0.00      0.00      0.00        26\n",
      "          29       0.00      0.00      0.00        42\n",
      "          30       0.00      0.00      0.00        59\n",
      "          31       0.00      0.00      0.00        56\n",
      "          32       0.00      0.00      0.00        40\n",
      "          33       0.00      0.00      0.00        53\n",
      "          34       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.76      3812\n",
      "   macro avg       0.47      0.47      0.47      3812\n",
      "weighted avg       0.76      0.76      0.76      3812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#Dummy inputs to load model\n",
    "xs=np.zeros((8446, 512))\n",
    "ys=np.zeros((8446, 35))\n",
    "xt=np.zeros((762, 512))\n",
    "yt=np.zeros((762, 35))\n",
    "weather_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=1.0, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "weather_model.fit(xs, ys,xt,yt, epochs=0,verbose=1,batch_size = 32) # NO fit happen, just dummy step to load model\n",
    "weather_model.load_weights(save_check_pt+ '/weather')\n",
    "weather_model.score(weather_images, weather_labels)\n",
    "weather_hat = weather_model.predict(weather_images)\n",
    "weather_hat = np.argmax(weather_hat,axis=1)\n",
    "weather_labels = np.argmax(weather_labels,axis=1)\n",
    "print(classification_report(weather_labels, weather_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8bd28db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 114ms/step - loss: 4.9436 - acc: 0.6770\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84        39\n",
      "           1       0.78      0.66      0.71        38\n",
      "           2       0.82      0.93      0.87        30\n",
      "           3       0.78      0.88      0.82        16\n",
      "           4       0.67      0.67      0.67         6\n",
      "           5       0.88      0.86      0.87        35\n",
      "           6       0.82      0.86      0.84        37\n",
      "           7       0.82      0.82      0.82        28\n",
      "           8       0.94      0.85      0.89        34\n",
      "           9       0.97      0.67      0.79        42\n",
      "          10       0.83      0.95      0.88        95\n",
      "          11       0.88      0.78      0.82         9\n",
      "          12       0.83      0.71      0.77         7\n",
      "          13       0.80      0.44      0.57         9\n",
      "          14       0.33      0.33      0.33         6\n",
      "          15       0.67      1.00      0.80         8\n",
      "          16       0.25      1.00      0.40         1\n",
      "          17       1.00      0.78      0.88         9\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.00      0.00      0.00         8\n",
      "          20       0.00      0.00      0.00         7\n",
      "          21       0.00      0.00      0.00         5\n",
      "          22       0.00      0.00      0.00         8\n",
      "          23       0.00      0.00      0.00         4\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         6\n",
      "          26       0.00      0.00      0.00        12\n",
      "          27       0.00      0.00      0.00        11\n",
      "          28       0.00      0.00      0.00         3\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       0.00      0.00      0.00         7\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       0.00      0.00      0.00         5\n",
      "          34       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.68       548\n",
      "   macro avg       0.40      0.40      0.39       548\n",
      "weighted avg       0.68      0.68      0.67       548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#Dummy inputs to load model\n",
    "xs=np.zeros((8446, 512))\n",
    "ys=np.zeros((8446, 35))\n",
    "xt=np.zeros((109, 512))\n",
    "yt=np.zeros((109, 35))\n",
    "challenge_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=1.0, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "challenge_model.fit(xs, ys,xt,yt, epochs=0,verbose=1,batch_size = 32) # NO fit happen, just dummy step to load model\n",
    "challenge_model.load_weights(save_check_pt+ '/challenge')\n",
    "challenge_model.score(challenge_images, challenge_labels)\n",
    "challenge_hat = challenge_model.predict(challenge_images)\n",
    "challenge_hat = np.argmax(challenge_hat,axis=1)\n",
    "challenge_labels = np.argmax(challenge_labels,axis=1)\n",
    "print(classification_report(challenge_labels, challenge_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aeef9b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step - loss: 4.7142 - acc: 0.7057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78       106\n",
      "           1       0.48      0.78      0.60        37\n",
      "           2       0.84      0.96      0.89       123\n",
      "           3       0.90      0.88      0.89       121\n",
      "           4       0.82      0.82      0.82        39\n",
      "           5       0.85      0.83      0.84       122\n",
      "           6       0.98      0.82      0.89       142\n",
      "           7       0.71      0.88      0.79        75\n",
      "           8       0.94      0.84      0.89       138\n",
      "           9       0.94      0.65      0.77       139\n",
      "          10       0.91      0.95      0.93       372\n",
      "          11       0.74      0.71      0.73        28\n",
      "          12       0.71      0.73      0.72        30\n",
      "          13       0.30      0.43      0.35        14\n",
      "          14       0.48      0.68      0.57        22\n",
      "          15       0.47      0.39      0.43        23\n",
      "          16       0.73      0.73      0.73        26\n",
      "          17       0.73      0.83      0.78        23\n",
      "          18       0.00      0.00      0.00        21\n",
      "          19       0.00      0.00      0.00        19\n",
      "          20       0.00      0.00      0.00        34\n",
      "          21       0.07      0.12      0.09        17\n",
      "          22       0.00      0.00      0.00        11\n",
      "          23       0.00      0.00      0.00        18\n",
      "          24       0.00      0.00      0.00         7\n",
      "          25       0.00      0.00      0.00        17\n",
      "          26       0.00      0.00      0.00        14\n",
      "          27       0.00      0.00      0.00        13\n",
      "          28       0.00      0.00      0.00        23\n",
      "          29       0.05      0.05      0.05        20\n",
      "          30       0.00      0.00      0.00         8\n",
      "          31       0.00      0.00      0.00        23\n",
      "          32       0.00      0.00      0.00        16\n",
      "          33       0.00      0.00      0.00        28\n",
      "          34       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.71      1869\n",
      "   macro avg       0.39      0.40      0.39      1869\n",
      "weighted avg       0.72      0.71      0.71      1869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#Dummy inputs to load model\n",
    "xs=np.zeros((8446, 512))\n",
    "ys=np.zeros((8446, 35))\n",
    "xt=np.zeros((373, 512))\n",
    "yt=np.zeros((373, 35))\n",
    "db_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=1.0, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "db_model.fit(xs, ys,xt,yt, epochs=0,verbose=1,batch_size = 32) # NO fit happen, just dummy step to load model\n",
    "db_model.load_weights(save_check_pt+ '/db')\n",
    "db_model.score(db_images, db_labels)\n",
    "db_hat = db_model.predict(db_images)\n",
    "db_hat = np.argmax(db_hat,axis=1)\n",
    "db_labels = np.argmax(db_labels,axis=1)\n",
    "print(classification_report(db_labels, db_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47a1c2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step - loss: 4.8389 - acc: 0.6708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        16\n",
      "           1       0.75      0.30      0.43        10\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       0.80      1.00      0.89         8\n",
      "           4       0.60      0.60      0.60         5\n",
      "           5       1.00      0.80      0.89        10\n",
      "           6       0.81      1.00      0.90        13\n",
      "           7       0.83      0.83      0.83        12\n",
      "           8       0.92      0.79      0.85        14\n",
      "           9       1.00      0.80      0.89        15\n",
      "          10       0.86      0.96      0.91        52\n",
      "          11       0.50      1.00      0.67         1\n",
      "          12       0.75      1.00      0.86         6\n",
      "          13       0.33      0.25      0.29         4\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.67      1.00      0.80         2\n",
      "          16       0.50      0.50      0.50         2\n",
      "          17       0.80      1.00      0.89         4\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         9\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         4\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         4\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         2\n",
      "          29       0.00      0.00      0.00         6\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         2\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67       243\n",
      "   macro avg       0.37      0.40      0.37       243\n",
      "weighted avg       0.66      0.67      0.66       243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#Dummy inputs to load model\n",
    "xs=np.zeros((8446, 512))\n",
    "ys=np.zeros((8446, 35))\n",
    "xt=np.zeros((48, 512))\n",
    "yt=np.zeros((48, 35))\n",
    "fn_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=1.0, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "fn_model.fit(xs, ys,xt,yt, epochs=0,verbose=1,batch_size = 32) # NO fit happen, just dummy step to load model\n",
    "fn_model.load_weights(save_check_pt+ '/fn')\n",
    "fn_model.score(fn_images, fn_labels)\n",
    "fn_hat = fn_model.predict(fn_images)\n",
    "fn_hat = np.argmax(fn_hat,axis=1)\n",
    "fn_labels = np.argmax(fn_labels,axis=1)\n",
    "print(classification_report(fn_labels, fn_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e233f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# img_h, img_w = 32,16\n",
    "# fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "# for i in range(6):\n",
    "#     ax = fig.add_subplot(2, 3, i+1)\n",
    "#     ax.imshow(weather_images[i].reshape([img_h, img_w]))\n",
    "\n",
    "#model.save_weights('ckpt')\n",
    "#dummy step to load model from checkpoint\n",
    "#xt = np.zeros((3812, 512))\n",
    "#nmd = DANN(lambda_=0.1, Xt=xt, metrics=[\"acc\"], random_state=0)\n",
    "#x = np.zeros((1,1))\n",
    "#y = np.zeros(1)\n",
    "#nmd.fit(x,y, epochs=0,verbose=1)\n",
    "#nmd.summary()\n",
    "#nmd.load_weights(\"ckpt\")\n",
    "#nmd.score(weather_images, weather_labels)\n",
    "\n",
    "#print(model.predict(weather_images[0].reshape([-1,512])))\n",
    "#y0 = model.predict(weather_images[0].reshape([-1,512]))\n",
    "#print(np.argmax(y0))\n",
    "# y_hat = model.predict(weather_images)\n",
    "# y_hat = np.argmax(y_hat,axis=1)\n",
    "# weather_labels = np.argmax(weather_labels,axis=1)\n",
    "# print(classification_report(weather_labels, y_hat))\n",
    "# y_hat = model.predict(base_images)\n",
    "# y_hat = np.argmax(y_hat,axis=1)\n",
    "# base_labels = np.argmax(base_labels,axis=1)\n",
    "# print(classification_report(base_labels, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
