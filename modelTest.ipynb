{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2410689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 32, 32, 3)\n",
      "(3812, 32, 32, 3)\n",
      "(762, 32, 32, 3)\n",
      "286/286 [==============================] - 24s 66ms/step - loss: 155.5574 - acc: 0.0404 - disc_loss: 4.0601 - disc_acc: 0.4755\n",
      "Model: \"dann\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Sequential)        (None, 35)                24656803  \n",
      "                                                                 \n",
      " task (Sequential)           (None, 1)                 371       \n",
      "                                                                 \n",
      " discriminator (Sequential)  (None, 1)                 371       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,657,545\n",
      "Trainable params: 1,068,809\n",
      "Non-trainable params: 23,588,736\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 3s 3s/step - loss: 160.8657 - acc: 0.0359\n"
     ]
    }
   ],
   "source": [
    "import  os, glob\n",
    "import  random, csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import adapt\n",
    "from adapt.feature_based import DANN\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# The path of the datasets, use dict format\n",
    "dataset_path = {\"base\": \"dataset/ccpd/splitted_plates_base\", \n",
    "                \"challenge\":\"dataset/ccpd/splitted_plates_challenge\",\n",
    "               \"db\":\"dataset/ccpd/splitted_plates_db\",\n",
    "               \"fn\":\"dataset/ccpd/splitted_plates_fn\",\n",
    "               \"weather\":\"dataset/ccpd/splitted_plates_weather\"}\n",
    "save_check_pt = './checkpoints/weather'\n",
    "my_epoch = 1\n",
    "\n",
    "def load_csv(root, filename, name2label):\n",
    "    # From csv file return images dir,labels list\n",
    "    if not os.path.exists(os.path.join(root, filename)):\n",
    "        images = []\n",
    "        for name in name2label.keys(): \n",
    "            images += glob.glob(os.path.join(root, name, '*.png'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpg'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpeg'))\n",
    "        #print(len(images), images)\n",
    "        random.shuffle(images) # shuffle images\n",
    "        with open(os.path.join(root, filename), mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for img in images:  \n",
    "                name = img.split(os.sep)[-2]\n",
    "                label = name2label[name]\n",
    "                writer.writerow([img, label])\n",
    "            print('written into csv file:', filename)\n",
    "    # read existed csv\n",
    "    images, labels = [], []\n",
    "    with open(os.path.join(root, filename)) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            img, label = row\n",
    "            label = int(label)\n",
    "            images.append(img)\n",
    "            labels.append(label) \n",
    "    # return img dir and label\n",
    "    return images, labels\n",
    "\n",
    "def load_ccpd(root, mode='train'):\n",
    "    name2label = {}  # \"sq...\":0\n",
    "    # iterate sub dir, sort, while keep mapping\n",
    "    for name in sorted(os.listdir(os.path.join(root))):\n",
    "        # skip non file folder\n",
    "        if not os.path.isdir(os.path.join(root, name)):\n",
    "            continue\n",
    "        # give each category a number\n",
    "        name2label[name] = len(name2label.keys())\n",
    "    images, labels = load_csv(root, 'images.csv', name2label)\n",
    "    if mode == 'train':  # 20%\n",
    "        images = images[:int(0.2 * len(images))]\n",
    "        labels = labels[:int(0.2 * len(labels))]\n",
    "    elif mode == 'val':  # 20% = 60%->80%\n",
    "        images = images[int(0.6 * len(images)):int(0.8 * len(images))]\n",
    "        labels = labels[int(0.6 * len(labels)):int(0.8 * len(labels))]\n",
    "    else:  # all\n",
    "        images = images\n",
    "        labels = labels\n",
    "    return images, labels, name2label\n",
    "\n",
    "def readCcpdImg(images_dir):\n",
    "    X = []\n",
    "    for img_dir in images_dir:\n",
    "        img = cv2.imread(img_dir)\n",
    "        img = cv2.resize(img,(32,32))\n",
    "        X.append(img)\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "def get_encoder(input_shape=(32,32,3)):\n",
    "    net = keras.applications.ResNet50(include_top=False,input_shape= input_shape, pooling=\"avg\")\n",
    "    net.trainable = False\n",
    "    newnet = keras.Sequential([\n",
    "        net, # drop last layer ResNet50\n",
    "        layers.Dense(512, activation='relu'), \n",
    "        layers.BatchNormalization(), \n",
    "        layers.Dropout(rate=0.5), \n",
    "        layers.Dense(35) # 35 category\n",
    "    ])\n",
    "    newnet.build(input_shape=input_shape)\n",
    "    newnet.compile(optimizer=Adam(0.01), loss='CategoricalCrossentropy')\n",
    "    return newnet\n",
    "\n",
    "def get_task(input_shape=(2,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=Adam(0.01), loss='mse')\n",
    "    return model\n",
    "\n",
    "def get_discriminator(input_shape=(2,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=Adam(0.01), loss='mse')\n",
    "    return model\n",
    "base_images_dir, base_labels, base_table = load_ccpd(dataset_path['base'],mode='all')\n",
    "base_images = readCcpdImg(base_images_dir)\n",
    "base_labels = np.array(base_labels)\n",
    "weather_images_dir, weather_labels, weather_table = load_ccpd(dataset_path['weather'],mode='all')\n",
    "weather_images = readCcpdImg(weather_images_dir)\n",
    "weather_labels = np.array(weather_labels)\n",
    "weather_images_dir_t, weather_labels_t, weather_table_t = load_ccpd(dataset_path['weather'],mode='train')\n",
    "weather_images_t = readCcpdImg(weather_images_dir_t)\n",
    "weather_labels_t = np.array(weather_labels_t)\n",
    "print(np.shape(base_images))\n",
    "print(np.shape(weather_images))\n",
    "print(np.shape(weather_images_t))\n",
    "model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=1.0, optimizer=Adam(0.001),  metrics=[\"acc\"],random_state=0)\n",
    "model.fit(base_images, base_labels,weather_images_t, epochs=my_epoch,verbose=1,batch_size = 32)\n",
    "model.summary()\n",
    "model.score(weather_images, weather_labels)\n",
    "model.save_weights(save_check_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60a86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# img_h, img_w = 32,16\n",
    "# fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "# for i in range(6):\n",
    "#     ax = fig.add_subplot(2, 3, i+1)\n",
    "#     ax.imshow(weather_images[i].reshape([img_h, img_w]))\n",
    "#model.save_weights('ckpt')\n",
    "#dummy step to load model from checkpoint\n",
    "#xt = np.zeros((3812, 512))\n",
    "#nmd = DANN(lambda_=0.1, Xt=xt, metrics=[\"acc\"], random_state=0)\n",
    "#x = np.zeros((1,1))\n",
    "#y = np.zeros(1)\n",
    "#nmd.fit(x,y, epochs=0,verbose=1)\n",
    "#nmd.summary()\n",
    "#nmd.load_weights(\"ckpt\")\n",
    "#nmd.score(weather_images, weather_labels)\n",
    "#print(nmd.predict(weather_images[0].reshape([-1,512])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
